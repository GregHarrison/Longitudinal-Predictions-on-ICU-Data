{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d859829-2b09-4d06-8217-92e00fae3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Conv1D, MaxPooling1D, Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18314c6-fc77-42a9-a30e-dedc6a9f1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176b217-fbee-4434-b3ae-096a1ea83311",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7acf37-cd45-491d-951b-69a1097d925f",
   "metadata": {},
   "source": [
    "## Pad Care Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04730e4f-0dc1-466d-8622-ff122985d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters = pd.read_hdf('./Data/encounters_agg.h5', 'encounters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e706f2a7-3e1d-4342-9a12-97518e9f101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the max number of care events per admission to train with\n",
    "sequence_length = 50\n",
    "\n",
    "encounter_list = []\n",
    "y_list = []\n",
    "\n",
    "# Loop through each admission\n",
    "for unique in encounters['HADM_ID'].unique():\n",
    "    adm = encounters[encounters['HADM_ID'] == unique].copy()\n",
    "    \n",
    "    if adm.shape[1] > 0:\n",
    "        # If patient survived less than 1 year after admission date append 1 to labels, else append 0\n",
    "        y_list.append(adm['1YEAR'].head(1).values[0])\n",
    "        adm.drop(['SUBJECT_ID', 'EID', '1YEAR', 'HADM_ID'], axis=1, inplace=True)\n",
    "\n",
    "        encounter_list.append(adm.values.tolist())\n",
    "        \n",
    "encounter_array = np.asarray(encounter_list, dtype=object)\n",
    "X = sequence.pad_sequences(encounter_array, maxlen=sequence_length, padding='post', truncating='post')\n",
    "y = np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4c18c889-dfa9-481f-8b1b-535d29bac501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7788, 35, 1721)\n",
      "[[24084     0     0 ...     0     0     0]\n",
      " [24084     0     0 ...     0     0     0]\n",
      " [24084     0     0 ...     0     0     0]\n",
      " ...\n",
      " [24084     0     0 ...     0     0     0]\n",
      " [24084     0     0 ...     0     0     0]\n",
      " [24084     0     0 ...     0     0     0]]\n",
      "Index(['SUBJECT_ID', '1YEAR', 'AGE', 'M', 'HADM_ID', 'EID', 'Government',\n",
      "       'Medicaid', 'Medicare', 'Private',\n",
      "       ...\n",
      "       'tpn 21 with heprin', 'tranexamic acid', 'ur cc/kg/hr', 'ur.cc/kg',\n",
      "       'ur.cc/kg/hr', 'urcc/kg/day', 'vac', 'vicu cryst', 'vicu u/o',\n",
      "       'while carevue down'],\n",
      "      dtype='object', length=1725)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X[0][:])\n",
    "print(encounters.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4aab3a9e-fea3-4731-9159-9088b9135733",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./Data/Xy.h5', 'w')\n",
    "h5f.create_dataset('X', data=X)\n",
    "h5f.create_dataset('y', data=y)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1283e4e-9d32-4591-a417-355c6d3045e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./Data/Xy.h5','r')\n",
    "X = h5f['X'][:]\n",
    "y = h5f['y'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c20c386-8af2-4f40-8aa9-4c7a3b7e68be",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88808e26-c53c-4fcc-8304-ed2c7de7068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "def mlp_fit_predict(X_train, y_train, X_test, y_test):    \n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(300, activation='relu'),\n",
    "        layers.Dense(300, activation='relu'),\n",
    "        layers.Dense(300, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['AUC']\n",
    "                 )\n",
    "    \n",
    "    case_proportion = (1-(sum(y_train)/float(len(y_train))))\n",
    "    \n",
    "    class_weights = {0: 1-case_proportion, 1: case_proportion}\n",
    "    print(class_weights)\n",
    "    print(sum(y_train), len(y_train), float(sum(y))/len(y))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=3)\n",
    "    \n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              validation_data=(X_test, y_test), \n",
    "              epochs=100, \n",
    "              batch_size=batch_size, \n",
    "              callbacks=[early_stopping],\n",
    "              class_weight=class_weights)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    mlp_pred = model.predict(X_test)\n",
    "    \n",
    "    return roc_auc_score(y_test, mlp_pred, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd838b04-5e78-4ec5-9109-27cab9a0845f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot model architecture\n",
    "mlp_model = tf.keras.Sequential([\n",
    "    layers.Flatten(input_shape=(X.shape[1], X.shape[2]), name=\"Input\"),\n",
    "    layers.Dropout(0.5, name=\"Dropout_1\"),\n",
    "    layers.Dense(300, activation='relu', name=\"Fully_Connected_1\"),\n",
    "    layers.Dense(300, activation='relu', name=\"Fully_Connected_2\"),\n",
    "    layers.Dense(300, activation='relu', name=\"Fully_Connected_3\"),\n",
    "    layers.Dropout(0.2, name=\"Dropout_2\"),\n",
    "    layers.Dense(1, activation='sigmoid', name= \"Output\")\n",
    "])\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    mlp_model, to_file='./Report/MLP.png', show_shapes=True, show_dtype=False,\n",
    "    show_layer_names=False, rankdir='LR', expand_nested=False, dpi=96 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98f99607-b81e-45e6-ad1c-ae2512faefab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.25939004815409317, 1: 0.7406099518459068}\n",
      "1616 6230 0.2593733949666153\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 3s 23ms/step - loss: 0.2645 - auc: 0.5871 - val_loss: 0.6049 - val_auc: 0.6138\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2570 - auc: 0.6313 - val_loss: 0.6434 - val_auc: 0.6492\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2502 - auc: 0.6736 - val_loss: 0.6379 - val_auc: 0.6597\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2420 - auc: 0.7073 - val_loss: 0.6295 - val_auc: 0.6689\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2399 - auc: 0.7092 - val_loss: 0.6347 - val_auc: 0.6657\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2347 - auc: 0.7136 - val_loss: 0.7533 - val_auc: 0.6725\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2307 - auc: 0.7340 - val_loss: 0.5558 - val_auc: 0.6804\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2324 - auc: 0.7236 - val_loss: 0.6112 - val_auc: 0.6867\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2227 - auc: 0.7557 - val_loss: 0.6010 - val_auc: 0.6777\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2175 - auc: 0.7676 - val_loss: 0.6251 - val_auc: 0.6862\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2221 - auc: 0.7511 - val_loss: 0.6334 - val_auc: 0.6834\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2112 - auc: 0.7859 - val_loss: 0.6608 - val_auc: 0.6810\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2085 - auc: 0.7948 - val_loss: 0.5706 - val_auc: 0.6893\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2116 - auc: 0.7891 - val_loss: 0.5974 - val_auc: 0.6918\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2034 - auc: 0.8055 - val_loss: 0.5647 - val_auc: 0.6713\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1976 - auc: 0.8233 - val_loss: 0.5524 - val_auc: 0.6619\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1966 - auc: 0.8223 - val_loss: 0.6078 - val_auc: 0.6787\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1919 - auc: 0.8325 - val_loss: 0.6702 - val_auc: 0.6744\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1813 - auc: 0.8560 - val_loss: 0.6128 - val_auc: 0.6753\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1781 - auc: 0.8612 - val_loss: 0.5857 - val_auc: 0.6877\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1765 - auc: 0.8613 - val_loss: 0.6550 - val_auc: 0.6691\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1718 - auc: 0.8722 - val_loss: 0.5959 - val_auc: 0.6545\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1644 - auc: 0.8806 - val_loss: 0.6546 - val_auc: 0.6535\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1617 - auc: 0.8869 - val_loss: 0.6028 - val_auc: 0.6667\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1587 - auc: 0.8911 - val_loss: 0.6428 - val_auc: 0.6650\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1564 - auc: 0.8956 - val_loss: 0.6106 - val_auc: 0.6456\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1501 - auc: 0.9065 - val_loss: 0.6610 - val_auc: 0.6608\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1428 - auc: 0.9126 - val_loss: 0.6428 - val_auc: 0.6520\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1390 - auc: 0.9158 - val_loss: 0.6830 - val_auc: 0.6494\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1259 - auc: 0.9318 - val_loss: 0.6906 - val_auc: 0.6480\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1385 - auc: 0.9209 - val_loss: 0.6977 - val_auc: 0.6455\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1329 - auc: 0.9272 - val_loss: 0.6666 - val_auc: 0.6435\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1297 - auc: 0.9304 - val_loss: 0.6449 - val_auc: 0.6533\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1262 - auc: 0.9327 - val_loss: 0.6889 - val_auc: 0.6432\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1150 - auc: 0.9437 - val_loss: 0.7181 - val_auc: 0.6246\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1168 - auc: 0.9425 - val_loss: 0.7125 - val_auc: 0.6441\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1085 - auc: 0.9510 - val_loss: 0.6980 - val_auc: 0.6357\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1023 - auc: 0.9564 - val_loss: 0.7306 - val_auc: 0.6359\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1011 - auc: 0.9576 - val_loss: 0.7556 - val_auc: 0.6427\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0995 - auc: 0.9589 - val_loss: 0.7674 - val_auc: 0.6574\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1016 - auc: 0.9581 - val_loss: 0.7203 - val_auc: 0.6385\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0974 - auc: 0.9608 - val_loss: 0.7355 - val_auc: 0.6615\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0969 - auc: 0.9614 - val_loss: 0.7309 - val_auc: 0.6538\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 300)               672300    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 853,201\n",
      "Trainable params: 853,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  0 {'mlp': [0.654771608010021]}\n",
      "{0: 0.25939004815409317, 1: 0.7406099518459068}\n",
      "1616 6230 0.2593733949666153\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 0.2629 - auc: 0.5677 - val_loss: 0.7335 - val_auc: 0.6292\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2557 - auc: 0.6282 - val_loss: 0.6905 - val_auc: 0.6570\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2494 - auc: 0.6715 - val_loss: 0.6635 - val_auc: 0.6728\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2403 - auc: 0.6969 - val_loss: 0.5844 - val_auc: 0.6800\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2397 - auc: 0.6904 - val_loss: 0.6075 - val_auc: 0.6819\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2375 - auc: 0.7078 - val_loss: 0.5818 - val_auc: 0.6804\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2404 - auc: 0.7029 - val_loss: 0.6549 - val_auc: 0.6906\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2308 - auc: 0.7277 - val_loss: 0.5996 - val_auc: 0.6889\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2282 - auc: 0.7359 - val_loss: 0.6261 - val_auc: 0.6968\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2254 - auc: 0.7405 - val_loss: 0.6202 - val_auc: 0.6989\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2222 - auc: 0.7594 - val_loss: 0.5360 - val_auc: 0.6942\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2186 - auc: 0.7628 - val_loss: 0.6901 - val_auc: 0.6949\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2177 - auc: 0.7756 - val_loss: 0.5882 - val_auc: 0.7004\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2144 - auc: 0.7734 - val_loss: 0.5847 - val_auc: 0.6817\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2056 - auc: 0.8003 - val_loss: 0.6261 - val_auc: 0.6959\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2053 - auc: 0.8011 - val_loss: 0.5940 - val_auc: 0.6865\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1996 - auc: 0.8128 - val_loss: 0.5830 - val_auc: 0.6856\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1942 - auc: 0.8310 - val_loss: 0.5604 - val_auc: 0.6875\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1866 - auc: 0.8404 - val_loss: 0.5790 - val_auc: 0.6905\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1838 - auc: 0.8415 - val_loss: 0.5622 - val_auc: 0.6842\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1811 - auc: 0.8543 - val_loss: 0.6211 - val_auc: 0.6761\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1784 - auc: 0.8593 - val_loss: 0.5643 - val_auc: 0.6855\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1780 - auc: 0.8570 - val_loss: 0.5550 - val_auc: 0.6903\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1640 - auc: 0.8796 - val_loss: 0.5712 - val_auc: 0.6856\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1550 - auc: 0.8968 - val_loss: 0.5666 - val_auc: 0.6797\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1598 - auc: 0.8900 - val_loss: 0.5769 - val_auc: 0.6822\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1459 - auc: 0.9076 - val_loss: 0.6654 - val_auc: 0.6904\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1540 - auc: 0.8967 - val_loss: 0.6017 - val_auc: 0.6684\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1470 - auc: 0.9067 - val_loss: 0.6383 - val_auc: 0.6739\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1411 - auc: 0.9163 - val_loss: 0.6485 - val_auc: 0.6817\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1389 - auc: 0.9194 - val_loss: 0.6413 - val_auc: 0.6769\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1301 - auc: 0.9289 - val_loss: 0.6710 - val_auc: 0.6867\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1407 - auc: 0.9181 - val_loss: 0.6094 - val_auc: 0.6919\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1164 - auc: 0.9429 - val_loss: 0.6172 - val_auc: 0.6751\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1237 - auc: 0.9367 - val_loss: 0.6452 - val_auc: 0.6800\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1161 - auc: 0.9425 - val_loss: 0.6537 - val_auc: 0.6727\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1146 - auc: 0.9450 - val_loss: 0.6934 - val_auc: 0.6737\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1187 - auc: 0.9428 - val_loss: 0.6688 - val_auc: 0.6774\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1100 - auc: 0.9503 - val_loss: 0.6837 - val_auc: 0.6733\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1006 - auc: 0.9579 - val_loss: 0.7062 - val_auc: 0.6737\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1044 - auc: 0.9549 - val_loss: 0.7407 - val_auc: 0.6684\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1050 - auc: 0.9539 - val_loss: 0.6766 - val_auc: 0.6803\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0955 - auc: 0.9621 - val_loss: 0.7090 - val_auc: 0.6592\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0950 - auc: 0.9627 - val_loss: 0.7504 - val_auc: 0.6685\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0948 - auc: 0.9628 - val_loss: 0.7568 - val_auc: 0.6567\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0866 - auc: 0.9685 - val_loss: 0.7139 - val_auc: 0.6847\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0842 - auc: 0.9712 - val_loss: 0.7943 - val_auc: 0.6707\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0889 - auc: 0.9671 - val_loss: 0.7362 - val_auc: 0.6686\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0815 - auc: 0.9722 - val_loss: 0.8285 - val_auc: 0.6594\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0854 - auc: 0.9704 - val_loss: 0.7533 - val_auc: 0.6722\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0827 - auc: 0.9718 - val_loss: 0.7833 - val_auc: 0.6675\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0802 - auc: 0.9730 - val_loss: 0.8413 - val_auc: 0.6672\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 300)               672300    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 853,201\n",
      "Trainable params: 853,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  1 {'mlp': [0.654771608010021, 0.6723321378931655]}\n",
      "{0: 0.25939004815409317, 1: 0.7406099518459068}\n",
      "1616 6230 0.2593733949666153\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 19ms/step - loss: 0.2652 - auc: 0.5561 - val_loss: 0.6560 - val_auc: 0.6556\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2557 - auc: 0.6209 - val_loss: 0.6880 - val_auc: 0.6756\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2512 - auc: 0.6658 - val_loss: 0.7006 - val_auc: 0.6818\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2406 - auc: 0.6935 - val_loss: 0.5982 - val_auc: 0.6911\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2366 - auc: 0.7153 - val_loss: 0.5721 - val_auc: 0.6934\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2366 - auc: 0.7132 - val_loss: 0.6982 - val_auc: 0.6916\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2322 - auc: 0.7336 - val_loss: 0.6318 - val_auc: 0.6978\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2286 - auc: 0.7384 - val_loss: 0.5809 - val_auc: 0.6862\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2256 - auc: 0.7464 - val_loss: 0.6247 - val_auc: 0.6942\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2179 - auc: 0.7659 - val_loss: 0.5623 - val_auc: 0.6834\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2114 - auc: 0.7796 - val_loss: 0.6338 - val_auc: 0.6951\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2127 - auc: 0.7794 - val_loss: 0.5574 - val_auc: 0.6864\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2109 - auc: 0.7833 - val_loss: 0.5640 - val_auc: 0.6874\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2022 - auc: 0.8069 - val_loss: 0.5899 - val_auc: 0.6926\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2014 - auc: 0.8061 - val_loss: 0.6272 - val_auc: 0.7051\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.2061 - auc: 0.7998 - val_loss: 0.6274 - val_auc: 0.6796\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1981 - auc: 0.8222 - val_loss: 0.5822 - val_auc: 0.6717\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1906 - auc: 0.8346 - val_loss: 0.6030 - val_auc: 0.6791\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1860 - auc: 0.8389 - val_loss: 0.5948 - val_auc: 0.6790\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1736 - auc: 0.8657 - val_loss: 0.5847 - val_auc: 0.6795\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1750 - auc: 0.8642 - val_loss: 0.5593 - val_auc: 0.6932\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1685 - auc: 0.8750 - val_loss: 0.5732 - val_auc: 0.6851\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1630 - auc: 0.8844 - val_loss: 0.5940 - val_auc: 0.6838\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.1626 - auc: 0.8850 - val_loss: 0.5779 - val_auc: 0.6740\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1571 - auc: 0.8928 - val_loss: 0.6089 - val_auc: 0.6838\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1563 - auc: 0.8929 - val_loss: 0.5889 - val_auc: 0.6879\n",
      "Epoch 27/100\n",
      " 9/25 [=========>....................] - ETA: 0s - loss: 0.1475 - auc: 0.9080"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2fb6de53ab39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mroc_auc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mlp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp_fit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cross fold: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-26602f7f324a>\u001b[0m in \u001b[0;36mmlp_fit_predict\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     31\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m               class_weight=class_weights)\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)\n",
    "roc_auc = {'mlp':[]}\n",
    "\n",
    "for i, (train, test) in enumerate(skf.split(X,y)):\n",
    "    roc_auc['mlp'].append(mlp_fit_predict(X[train], y[train], X[test], y[test]))\n",
    "    print('Cross fold: ', i, roc_auc)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd66c8-89f1-4268-9a30-0b3fc805213e",
   "metadata": {},
   "source": [
    "# Training Feed Forward Neural Network Using a Varied Number of Care Events Per Admission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb26cf39-04db-466b-948c-9892d016e09d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.25939004815409317, 1: 0.7406099518459068}\n",
      "1616 6230 0.2593733949666153\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 4s 99ms/step - loss: 84.6687 - auc: 0.5165 - val_loss: 30.4231 - val_auc: 0.5564\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 14.8672 - auc: 0.5283 - val_loss: 13.7896 - val_auc: 0.5710\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 7.0440 - auc: 0.5394 - val_loss: 13.1213 - val_auc: 0.5796\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 3.8156 - auc: 0.5357 - val_loss: 4.9048 - val_auc: 0.6076\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 2.2600 - auc: 0.5552 - val_loss: 1.4196 - val_auc: 0.6259\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.8402 - auc: 0.5569 - val_loss: 1.0509 - val_auc: 0.6439\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.3795 - auc: 0.5729 - val_loss: 0.7042 - val_auc: 0.6281\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.2951 - auc: 0.5893 - val_loss: 0.6448 - val_auc: 0.6351\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2737 - auc: 0.5992 - val_loss: 0.6657 - val_auc: 0.65590s - loss: 0.2747 - auc: 0.5\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 0.2747 - auc: 0.6280 - val_loss: 0.6767 - val_auc: 0.6677\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2654 - auc: 0.6348 - val_loss: 0.6685 - val_auc: 0.6659\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2618 - auc: 0.6210 - val_loss: 0.6680 - val_auc: 0.6715\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 2s 82ms/step - loss: 0.2563 - auc: 0.6343 - val_loss: 0.6643 - val_auc: 0.6676\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.2515 - auc: 0.6463 - val_loss: 0.6451 - val_auc: 0.6487\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2638 - auc: 0.6246 - val_loss: 0.6645 - val_auc: 0.6604\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.2615 - auc: 0.6496 - val_loss: 0.6723 - val_auc: 0.6588\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2478 - auc: 0.6454 - val_loss: 0.6725 - val_auc: 0.6671 - loss: 0.2476 - auc:\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 2s 82ms/step - loss: 0.2470 - auc: 0.6674 - val_loss: 0.6668 - val_auc: 0.6652\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2489 - auc: 0.6521 - val_loss: 0.6508 - val_auc: 0.6610\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2460 - auc: 0.6635 - val_loss: 0.6636 - val_auc: 0.6719\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.2482 - auc: 0.6618 - val_loss: 0.6465 - val_auc: 0.6496\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 120470)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 120470)            0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 300)               36141300  \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 36,322,201\n",
      "Trainable params: 36,322,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  0 {'mlp': [0.646087864852343]}\n",
      "{0: 0.25939004815409317, 1: 0.7406099518459068}\n",
      "1616 6230 0.2593733949666153\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 14s 568ms/step - loss: 84.2001 - auc: 0.5004 - val_loss: 45.4723 - val_auc: 0.57410s - loss: 100.2982 - auc: 0.495 - ETA: 0s - loss: 98.8198  - ETA: 0s - loss: 89.7156 - a\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 2s 94ms/step - loss: 15.0518 - auc: 0.5245 - val_loss: 8.1497 - val_auc: 0.5632\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 2s 86ms/step - loss: 6.7177 - auc: 0.5350 - val_loss: 8.1121 - val_auc: 0.5871\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 2.7308 - auc: 0.5255 - val_loss: 1.1651 - val_auc: 0.5064\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.9912 - auc: 0.5359 - val_loss: 0.6906 - val_auc: 0.5741\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.4656 - auc: 0.5384 - val_loss: 0.6535 - val_auc: 0.5614\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.4038 - auc: 0.5620 - val_loss: 0.6620 - val_auc: 0.5438\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.3651 - auc: 0.5378 - val_loss: 0.6682 - val_auc: 0.5546\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 2s 93ms/step - loss: 0.3408 - auc: 0.5471 - val_loss: 0.6569 - val_auc: 0.5535\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.3238 - auc: 0.5358 - val_loss: 0.6482 - val_auc: 0.5470\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.2788 - auc: 0.5646 - val_loss: 0.6568 - val_auc: 0.5446\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 2s 94ms/step - loss: 0.2894 - auc: 0.5582 - val_loss: 0.6507 - val_auc: 0.5431\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2846 - auc: 0.5620 - val_loss: 0.6800 - val_auc: 0.5590\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 2s 84ms/step - loss: 0.2818 - auc: 0.5482 - val_loss: 0.6533 - val_auc: 0.5405\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 2s 87ms/step - loss: 0.2890 - auc: 0.5485 - val_loss: 0.6525 - val_auc: 0.5430\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 2s 87ms/step - loss: 0.2795 - auc: 0.5486 - val_loss: 0.6546 - val_auc: 0.5405\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 2s 93ms/step - loss: 0.2817 - auc: 0.5522 - val_loss: 0.6534 - val_auc: 0.5467\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.2621 - auc: 0.5524 - val_loss: 0.6527 - val_auc: 0.5493\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.2600 - auc: 0.5560 - val_loss: 0.6533 - val_auc: 0.5494\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 2s 84ms/step - loss: 0.2839 - auc: 0.5416 - val_loss: 0.6554 - val_auc: 0.5439\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2651 - auc: 0.5523 - val_loss: 0.6552 - val_auc: 0.5492\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 2s 82ms/step - loss: 0.2683 - auc: 0.5599 - val_loss: 0.6572 - val_auc: 0.5479\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 120470)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 120470)            0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 300)               36141300  \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 36,322,201\n",
      "Trainable params: 36,322,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  1 {'mlp': [0.646087864852343, 0.5478876743826896]}\n",
      "{0: 0.25939004815409317, 1: 0.7406099518459068}\n",
      "1616 6230 0.2593733949666153\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 8s 173ms/step - loss: 128.6210 - auc: 0.5087 - val_loss: 22.7490 - val_auc: 0.41601s - loss: 163.5209 - auc: 0.51 - ETA: 1s - loss: 155.1652 - auc: - ETA: 0s - loss: 133.3095 - auc: 0.509\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 17.0360 - auc: 0.5208 - val_loss: 44.9010 - val_auc: 0.5833\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 2s 86ms/step - loss: 10.1926 - auc: 0.5139 - val_loss: 4.8317 - val_auc: 0.5905\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 6.1576 - auc: 0.5287 - val_loss: 7.3816 - val_auc: 0.6102\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 3.8311 - auc: 0.5364 - val_loss: 4.1278 - val_auc: 0.6178\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 2s 82ms/step - loss: 2.9048 - auc: 0.5248 - val_loss: 1.4538 - val_auc: 0.5462\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 2.2331 - auc: 0.5443 - val_loss: 0.6518 - val_auc: 0.6240\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 1.0185 - auc: 0.5584 - val_loss: 0.5939 - val_auc: 0.5527\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.3301 - auc: 0.5408 - val_loss: 0.6150 - val_auc: 0.5506\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.2771 - auc: 0.5460 - val_loss: 0.6265 - val_auc: 0.5489\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 0.2708 - auc: 0.5531 - val_loss: 0.6311 - val_auc: 0.5501\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2640 - auc: 0.5483 - val_loss: 0.6353 - val_auc: 0.5462\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2673 - auc: 0.5438 - val_loss: 0.6356 - val_auc: 0.5520\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2667 - auc: 0.5511 - val_loss: 0.6381 - val_auc: 0.5547\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 0.2586 - auc: 0.5479 - val_loss: 0.6400 - val_auc: 0.5480\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 0.2625 - auc: 0.5641 - val_loss: 0.6409 - val_auc: 0.5536\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 0.2549 - auc: 0.5558 - val_loss: 0.6422 - val_auc: 0.5493\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 0.2544 - auc: 0.5418 - val_loss: 0.6443 - val_auc: 0.5493\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 0.2610 - auc: 0.5440 - val_loss: 0.6461 - val_auc: 0.5480\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 0.2622 - auc: 0.5490 - val_loss: 0.6463 - val_auc: 0.5525\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2552 - auc: 0.5452 - val_loss: 0.6473 - val_auc: 0.5493\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2603 - auc: 0.5554 - val_loss: 0.6483 - val_auc: 0.5553\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2539 - auc: 0.5561 - val_loss: 0.6493 - val_auc: 0.5553\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2611 - auc: 0.5469 - val_loss: 0.6503 - val_auc: 0.5509\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 120470)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 120470)            0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 300)               36141300  \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 36,322,201\n",
      "Trainable params: 36,322,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  2 {'mlp': [0.646087864852343, 0.5478876743826896, 0.5508841395404704]}\n",
      "{0: 0.2593484191943508, 1: 0.7406515808056492}\n",
      "1616 6231 0.2593733949666153\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 4s 136ms/step - loss: 132.4197 - auc: 0.5035 - val_loss: 50.0132 - val_auc: 0.5579\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 18.0941 - auc: 0.5310 - val_loss: 10.5163 - val_auc: 0.5597\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 2s 84ms/step - loss: 8.7044 - auc: 0.5311 - val_loss: 2.7794 - val_auc: 0.5895\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 5.3684 - auc: 0.5281 - val_loss: 10.9804 - val_auc: 0.6098\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 2s 85ms/step - loss: 3.5082 - auc: 0.5433 - val_loss: 1.7947 - val_auc: 0.6562\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 1.6904 - auc: 0.5250 - val_loss: 1.2147 - val_auc: 0.6730\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 2s 82ms/step - loss: 0.7098 - auc: 0.5616 - val_loss: 0.7328 - val_auc: 0.6837\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.3451 - auc: 0.5751 - val_loss: 0.6464 - val_auc: 0.5080 loss: 0.3471 - auc: 0.5\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.2834 - auc: 0.5768 - val_loss: 0.6609 - val_auc: 0.6910\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2620 - auc: 0.6172 - val_loss: 0.6897 - val_auc: 0.6899\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.2577 - auc: 0.6397 - val_loss: 0.6717 - val_auc: 0.6950\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 2s 82ms/step - loss: 0.2611 - auc: 0.6392 - val_loss: 0.6699 - val_auc: 0.6857\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2508 - auc: 0.6334 - val_loss: 0.6916 - val_auc: 0.6866\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2532 - auc: 0.6488 - val_loss: 0.6537 - val_auc: 0.6862\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.2533 - auc: 0.6214 - val_loss: 0.6656 - val_auc: 0.6911\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 0.2508 - auc: 0.6641 - val_loss: 0.6607 - val_auc: 0.6898\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 2s 84ms/step - loss: 0.2504 - auc: 0.6447 - val_loss: 0.6715 - val_auc: 0.6896\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2506 - auc: 0.6522 - val_loss: 0.6587 - val_auc: 0.6884\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.2476 - auc: 0.6524 - val_loss: 0.6387 - val_auc: 0.6856\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2491 - auc: 0.6347 - val_loss: 0.6693 - val_auc: 0.6891\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2475 - auc: 0.6490 - val_loss: 0.6668 - val_auc: 0.6887\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.2461 - auc: 0.6480 - val_loss: 0.6736 - val_auc: 0.6885\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2489 - auc: 0.6462 - val_loss: 0.6680 - val_auc: 0.6899\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 2s 82ms/step - loss: 0.2507 - auc: 0.6486 - val_loss: 0.6574 - val_auc: 0.6886\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.2470 - auc: 0.6682 - val_loss: 0.6777 - val_auc: 0.6914\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 2s 84ms/step - loss: 0.2522 - auc: 0.6504 - val_loss: 0.6369 - val_auc: 0.6871\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.2506 - auc: 0.6222 - val_loss: 0.6434 - val_auc: 0.6886\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.2504 - auc: 0.6291 - val_loss: 0.6708 - val_auc: 0.6882\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 120470)            0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 120470)            0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 300)               36141300  \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 36,322,201\n",
      "Trainable params: 36,322,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  3 {'mlp': [0.646087864852343, 0.5478876743826896, 0.5508841395404704, 0.6880136192283582]}\n",
      "{0: 0.2593484191943508, 1: 0.7406515808056492}\n",
      "1616 6231 0.2593733949666153\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 4s 113ms/step - loss: 115.2083 - auc: 0.5115 - val_loss: 114.2613 - val_auc: 0.5513\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 20.7128 - auc: 0.5221 - val_loss: 31.7940 - val_auc: 0.5625\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 8.8023 - auc: 0.5310 - val_loss: 7.7439 - val_auc: 0.4727\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 2s 85ms/step - loss: 6.7110 - auc: 0.5137 - val_loss: 5.1810 - val_auc: 0.5819\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 3.5961 - auc: 0.5396 - val_loss: 8.4515 - val_auc: 0.5898\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 2.3736 - auc: 0.5623 - val_loss: 2.7601 - val_auc: 0.6238\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 1.1709 - auc: 0.5584 - val_loss: 1.9171 - val_auc: 0.6020\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.5719 - auc: 0.5768 - val_loss: 0.7472 - val_auc: 0.5969\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.3298 - auc: 0.5994 - val_loss: 0.6886 - val_auc: 0.5952\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2858 - auc: 0.6294 - val_loss: 0.6982 - val_auc: 0.6298\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 0.2715 - auc: 0.6476 - val_loss: 0.7018 - val_auc: 0.6235\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 2s 84ms/step - loss: 0.2529 - auc: 0.6471 - val_loss: 0.7360 - val_auc: 0.6295\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2538 - auc: 0.6483 - val_loss: 0.6966 - val_auc: 0.6209\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 0.2510 - auc: 0.6335 - val_loss: 0.7048 - val_auc: 0.6286\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2587 - auc: 0.6468 - val_loss: 0.7189 - val_auc: 0.6239\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2562 - auc: 0.6334 - val_loss: 0.6775 - val_auc: 0.6272\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2505 - auc: 0.6604 - val_loss: 0.6833 - val_auc: 0.6240\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.2518 - auc: 0.6487 - val_loss: 0.6601 - val_auc: 0.6186\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.2562 - auc: 0.6356 - val_loss: 0.7080 - val_auc: 0.6272\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2500 - auc: 0.6693 - val_loss: 0.6778 - val_auc: 0.6350\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2481 - auc: 0.6532 - val_loss: 0.6856 - val_auc: 0.6264\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.2640 - auc: 0.6588 - val_loss: 0.6952 - val_auc: 0.6300\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 2s 82ms/step - loss: 0.2485 - auc: 0.6624 - val_loss: 0.7149 - val_auc: 0.6289\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2483 - auc: 0.6604 - val_loss: 0.6990 - val_auc: 0.6251\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2478 - auc: 0.6649 - val_loss: 0.6850 - val_auc: 0.6249\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.2459 - auc: 0.6549 - val_loss: 0.6962 - val_auc: 0.6210\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 0.2450 - auc: 0.6677 - val_loss: 0.7112 - val_auc: 0.62600s - loss: 0.2429 - auc: 0 - ETA: 0s - loss: 0.2440 - auc:\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 0.2468 - auc: 0.6606 - val_loss: 0.7117 - val_auc: 0.6269\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 0.2451 - auc: 0.6800 - val_loss: 0.6936 - val_auc: 0.6275\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 120470)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 120470)            0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 300)               36141300  \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 36,322,201\n",
      "Trainable params: 36,322,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  4 {'mlp': [0.646087864852343, 0.5478876743826896, 0.5508841395404704, 0.6880136192283582, 0.6282255502219779]}\n"
     ]
    }
   ],
   "source": [
    "mlp_scores = {}\n",
    "# use cross fold from above, training separately to tune LSTM\n",
    "for i in [1, 3, 5, 10, 20, 30, 50, 70]:\n",
    "    encounter_list = []\n",
    "    y = []\n",
    "    \n",
    "    # Loop through each admission\n",
    "    for admission in encounters['HADM_ID'].unique():\n",
    "        adm = encounters[encounters['HADM_ID'] == admission].copy()\n",
    "\n",
    "        if adm.shape[1] > 0:\n",
    "            y.append(adm['1YEAR'].head(1).values[0])\n",
    "            adm.drop(['SUBJECT_ID', 'EID', '1YEAR', 'HADM_ID'], axis=1, inplace=True)\n",
    "            encounter_list.append(adm.values.tolist())\n",
    "\n",
    "    X = sequence.pad_sequences(np.array(encounter_list, dtype=object), \n",
    "                               maxlen=i, \n",
    "                               padding='post', \n",
    "                               truncating='post')\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Train Model\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)\n",
    "    score = {'mlp':[]}\n",
    "    \n",
    "    for j, (train, test) in enumerate(skf.split(X, y)):\n",
    "        score['mlp'].append(mlp_fit_predict(X[train], y[train], X[test], y[test]))\n",
    "        print('Cross fold: ', j, score)\n",
    "    mlp_scores[i] = score\n",
    "pkl.dump(mlp_scores, open('./Model_Scores/mlp_scores.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10f588f0-6768-4c9d-bffc-0e36dff3c233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'mlp': [0.44671461296909587,\n",
       "   0.6782124594608507,\n",
       "   0.6974042074918063,\n",
       "   0.6671972813066216,\n",
       "   0.4122983091891149]},\n",
       " 3: {'mlp': [0.6396981227585496,\n",
       "   0.680763851948453,\n",
       "   0.4283164884946033,\n",
       "   0.6678595656616833,\n",
       "   0.6696102719552094]},\n",
       " 5: {'mlp': [0.6417047033992828,\n",
       "   0.6840734766717573,\n",
       "   0.6800581704617602,\n",
       "   0.6647166668097859,\n",
       "   0.6691701802443905]},\n",
       " 10: {'mlp': [0.6409496885563774,\n",
       "   0.6806319388437978,\n",
       "   0.5519930675909879,\n",
       "   0.6690445930976446,\n",
       "   0.6608299056271628]},\n",
       " 20: {'mlp': [0.5456612385675309,\n",
       "   0.674339790998164,\n",
       "   0.672038282684421,\n",
       "   0.6786911887199127,\n",
       "   0.6572415480923635]},\n",
       " 30: {'mlp': [0.6479807642809341,\n",
       "   0.6774864011531135,\n",
       "   0.6715170650513925,\n",
       "   0.6986166092758452,\n",
       "   0.6392214026259521]},\n",
       " 50: {'mlp': [0.5429693532611494,\n",
       "   0.6842010999193507,\n",
       "   0.6813000840811984,\n",
       "   0.6871484633285532,\n",
       "   0.6278305410766576]},\n",
       " 70: {'mlp': [0.646087864852343,\n",
       "   0.5478876743826896,\n",
       "   0.5508841395404704,\n",
       "   0.6880136192283582,\n",
       "   0.6282255502219779]}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddba4bfc-6349-4cdf-893c-0c70646def2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'AUC ROC')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(7,7))\n",
    "\n",
    "plt.boxplot([mlp_scores[i]['mlp'] for i in [1, 3, 5, 10, 20, 30, 50, 70]], \n",
    "            labels=['1', '3', '5', '10', '20', '30', '50', '70'], \n",
    "            widths=0.75,\n",
    "            patch_artist=True,\n",
    "            boxprops=dict(facecolor='grey', color='grey'),\n",
    "            capprops=dict(color='grey'),\n",
    "            whiskerprops=dict(color='grey'),\n",
    "            flierprops=dict(color='grey', markeredgecolor='grey'),\n",
    "            medianprops=dict(color='black')\n",
    "           )\n",
    "\n",
    "plt.grid(axis='x')\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel('Number of Care Events per Admission', fontsize=16)\n",
    "plt.ylabel('AUC ROC', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb11cf-f969-4be0-8af8-4536eb04a9a7",
   "metadata": {},
   "source": [
    "# Training LSTM Using a Varied Number of Care Events Per Admission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1ea292f-b795-4428-b1bd-e300ff975273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_fit_predict(X_train, y_train, X_test, y_test):    \n",
    "    model = tf.keras.Sequential([\n",
    "        layers.LSTM(100, return_sequences=True, stateful=False, input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "                    recurrent_dropout=0.4, dropout=0.5),\n",
    "        layers.LSTM(50, return_sequences=True, dropout=0.5, recurrent_dropout=0.3, stateful=False),\n",
    "        layers.LSTM(50, return_sequences=False, dropout=0.5, recurrent_dropout=0.3, stateful=False),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['AUC'])\n",
    "    \n",
    "    case_proportion = (1-(sum(y_train)/float(len(y_train))))\n",
    "    class_weights = {0: 1-case_proportion, 1: case_proportion}\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=3)\n",
    "    \n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              validation_data=(X_test, y_test), \n",
    "              epochs=100, \n",
    "              batch_size=256, \n",
    "              callbacks=[early_stopping],\n",
    "              class_weight=class_weights)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    lstm_pred = model.predict(X_test)\n",
    "    \n",
    "    return roc_auc_score(y_test, lstm_pred, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd1b7e12-39e1-4712-9cb3-51050e885064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABeQAAABoCAIAAAAfEGc7AAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3dfYwcZR3A8Wd6baMFewc1VxLayh9NoRC8RBO8IxoiFpCLc9R4LxSpaNKXvShIgRipewFtQ0zcgxrB1rv+YVNh76X/cAshGHoJTeiuSU3uog1eUfSOFrKrkF1eEuVt/OOhw3Rmdm92b16emf1+/mhuZ+flt8/v9zyz+3R2VjMMQwAAAAAAAEANy6IOAAAAAAAAAJ9isgYAAAAAAEAhTNYAAAAAAAAohMkaAAAAAAAAhSy3Psjn848++mhUoQBYusnJyahD+ATjCRCcrq6u++67L+ooPvHoo4/m8/moowBigHM04Iv77ruvq6sr6ig+0dfXF3UISA5bbV9wZc1rr7127Nix0EMC4IOzZ88q1X8ZT4CAFAoFpSZH8vl8oVCIOgpAaZyjAb8cO3bstddeizqKTx07duzs2bNRR4EkcNb2cudK6sz6A/BuYmJiYGAg6ijsGE8A3yn4n3idnZ10dqAGztGAXzRNizoEuz179vT390cdBWLPWdvcswYAAAAAAEAhTNYAAAAAAAAohMkaAAAAAAAAhTBZAwAAAAAAoBAmawAAAAAAABTCZA0AAAAAAIBCmKyJhuYQ0IEqlYq589AOCiAcHjt1oVAYHBzUNG1wcHB6err2sFBboVBw3T8DC7B09GggWvRBwMm1dIeHh3O5XKVSiTq6hGOyJhqGYZTLZfl3uVw2DCOgA504ccJ60GKxGMJBAYTDS6cuFApdXV033HCDYRgHDx5cs2bN9u3brStks1njPHO3UjablQ/n5+flU0eOHHEewlxYLBYZWICG0aOBaNEHASdnvzAMY8uWLaOjo9u3by+VStGGl2xM1kSmtbXV9ofvKpXK6OiodUl7e3vQBwUQpkU7tXzPd/vtt8uHHR0d+/bts65gPuV06623yj82bNgghMhkMocOHVpYWLCus7CwsHHjRlswABpDjwaiRR8EnJz9oqOj4/Dhw0KIHTt2cH1NcJisUUWpVBobG+vp6RFC5HI5TdN6enrk8F0qlXK5nHxqdHRUXnV55swZuaHtIknrw0wmk8vlzIVewpDzO3L9oaGhUqk0PDxsveBNrmYuNCOUS3p6eqanp60xVyqVwcHBoaEhX1sLgFfnzp0TQszOzppLOjo6zL/N/9xz1draal1hy5YtQoiTJ09a1zl58qRcDiAE9GggWvRBQGpvb7/33ntzuZz1mxyunwqrfciV5Pqjo6OlUsn6idW5q2ZkWIyPj9uWIFDWFOi6Lh/m83nj/OWRqVTKsFz9KJ8ql8upVEoIMTc3Z1guS5P7Mc8BzkNUW2Il91wsFq0B5PN582+Truvy4sxisajrurzm8/jx40KImZkZ68uZmZmxbYsgqNZ/VYsnwWp36pmZGbnCyMiIefFqA7uSy+UQYV1uHabqDh0N6e3t7e3tjTqKT6kWT9zRoxNJtXOiavEohT6oOCHE+Ph41FF8SrV4AuJak/K2HuYHvUU/FRoXfsg1DCOTyczPz8tdpdNp8xCuuwrlhUbJWUtM1kTJVvQ1HtqekueJTCZT74auS6zS6bTZeaxrZjIZIYTsSzIA8xu55vdvza3S6bS5+aKnMfhFtf6rWjwJtuhburm5Ofl2UAiRzWZr9MpF31bK86U83RqGMTMzc/z4cS8xwEeqTY6oFk/c0aMTSbVzomrxKIU+qDjVJkdUiycg1WrSurz2p0LXTcT5ezMZ5y9BqL2rZHPWEl+DiiV5veUDDzzg+5737dt38ODBhYUF8xtPkrwg8/nnn5cPX3jhheuvv17+/dRTT4kLv361f/9+c0NujgNEbtOmTQcPHszn86lUatu2bW1tbfILkg248cYbheXeh8eOHZNLAISGHg1Eiz4IuKr9qdBVKpVau3bt2NhYpVJpb283zk/lNLCrRGKyBnajo6M/+tGPzCvWpI6OjlQqtWvXrkqlUqlU/v73v8tbowkh5PnJOS8IQCmdnZ3yzaWu6z09PQ2/s8xms/KGiKVS6ZprrvE3SAAe0aOBaNEHAXlrYfn1JdHQp8I9e/boui4nPa3XCvABU2KyJsbMKzB9MTg4KIQYGxvbtWvX448/vmnTJtfDPffccydOnLjrrrtsz5o3PAagCNmpNU2z3qW/s7Pz8ccfF0LIO701QF5Vd/LkyenpafMKOwBBo0cD0aIPAjZ//vOfhRBf//rXrQvr+lS4adOmqakpeYfTBx54wPbdDj5gMlkTS7Jwu7u7/dphoVC44YYbhBDbtm0T539Q0EZeXLNt27bR0dHOzk5z+cjIiBDi6NGj8tQlb9ztV2AAGmN2anH+VGqSHdx29Zx3GzZsSKfT27ZtO3funOtYAcB39GggWvRBwKZUKh04cEDXdfO7ew18KpSznx0dHQcPHpyZmTHv8sEHTInJmsiYs/JmCVofms+ay4UQY2Nj8qmjR4/qum6eFeQ1L3IGp1AoyIVy+l+uY9a3dW+mQqHQ1dW1efNmc/2FhQVzItO6ibygxnY2uu2224QQ+/fvb2tr0zRt7dq1fX19rgcC4LtFO7UQ4hvf+Mb09LQ5tsiRZN++fdV25dynXGIu7+3tFedvZVV7QwB1oUcD0aIPAk62z61CiNnZ2R07dgghDh8+bK5W+1NhtQ+5mUxG/pL3JZdcIn/Tptqugn2RSmKyJhqaprW1tcm/zRI0H5r/CiHM5UKIzZs39/T0tLW1bdiw4ejRo+byBx98UNf1K6+8MpfLdXZ2yt85+/nPfy7Onzl+85vfbN++3XoUzaKrq0sIccUVV5jrj46OtrW1yV+G+u9//2seSO7c/I8Fqb29fX5+Xn5ZMZVKzc/Pb9iwwTxQwxeFAliUl04thDAMY926dRMTE3LkOX369NzcnLxPueuu1q5dK+/lZnvKXC6vs5N7qLEhgLrQo4Fo0QcBJ+fnVk3TXnjhhb17905NTbW3t5tr1v5UWO1D7t133z05Oalp2uTk5P33319jV2G8WsVo1lv1TExMDAwMNOfNexQnR+rIU1OpVH76058ePHgw2jDgSrX+q1o8QGLI/1yanJyMOpBPqBYPoCDVzomqxQN4p2na+Ph4f39/1IF8QrV4EF/OWuLKGtRhYmKiOa9AAwAAAAAgNEzWxEDk31wdGhqSF7wtLCyYd5ACAAAAAABBWB51AFic9ZurkVywKr8iODIysnPnzvCPDgAAAABAU2GyJgYi/0bxzp07maYBAAAAACAcfA0KAAAAAABAIUzWAAAAAAAAKITJGgAAAAAAAIUwWQMAAAAAAKAQJmsAAAAAAAAU4vJrUJqmhR8HgERiPAGC0NvbG3UIFzh27BidHYgdui3gi4GBgYGBgaijQAK5TNaMj4+HHwd8NzAwcO+993Z1dUUdCEKSz+cPHDgQdRR2jCdqYnyItcceeyzqEOw6Ozv37NkTdRRNStYD7a84ztEJRh8MmYLTIrynsuF9ZmOcte0yWdPf3x9KMAjWwMBAV1cX2WwqCr4RpALVxPgQa5OTk1GHYLdu3TrKKSqyHmh/9XGOTir6YMgUnKzhPZUN7zMb46xt7lkDAAAAAACgECZrAAAAAAAAFMJkDQAAAAAAgEKYrAEAAAAAAFAIkzUAAAAAAAAKifFkzdDQ0NDQUNRRAIgTxg0gqejdgLLonoB39BeYYjxZE7RKpaJpWtRRYBF+pYl0wxcUUiQYBxACyiM4dGEsEan3go4GqakyGPeyXx7+If2yb9++QPd/4sSJQPcPX/iVJtLt3aFDh7q7uzds2BB1II1g3EgkxoEgnD59em5urru7+zOf+UzUsXhC744vurCPnnjiia1bt15++eVRB3IBuqcK6Gh1eeaZZ9asWdPZ2Rn+R3T6i4/iXvZcWeOuUqmMjo5GHQUW4VeaSHdd0un0FVdc0dXVdfDgwf/85z9Rh6MQCikSjAMB+cc//vGd73zn85///Pe///0//vGPH330UdQRRYnyCA5d2F8/+clP1q9f/7WvfW10dPStt96KOpwwkHov6Gj1euaZZ66//vr169f/7Gc/++tf/xp1OL5pngyKRJR9XCdrSqXS2NhYT0+P7e9cLqdpWk9Pz8LCgnwql8vJp0ZHRzVNGxwcPHPmjNyJdp7zYSaTyeVy5kLBtweDV6lUxsbGZIOPjo6WSiW53HuaSHc4Pv74Y8Mw/vSnP919992XXXbZzTff/Ic//OGdd96JOq7FMW6oj3FANe+9996TTz55yy23tLe333PPPfl83jCMqINyQe9WBF04coZhGIbx0ksvpVKptWvXdnd3Z7PZ9957L8KQ6J6+o6OFo6Wl5dy5c7/61a+uvfbaq6666pe//OW//vWvoA9Kf6mmScvesBgfH7ctUZau62b85t/yTeT8/LwQIpVKGZY3lPKpcrmcSqWEEHNzc4ZhFItFayPIDc2HtvZJp9PpdDrcV7kkQojx8fGoo6iDrusjIyOGYRSLRV3XdV0vl8tGPWlq5nQbIfbfSy65xDqGtLS0LFu2bMWKFd3d3UeOHHnvvfdCjsc7xg2TsuMD44AXvb29vb29QR/l6aefFhdauXKlEGLt2rX33HPPqVOnQo6ntmbu3Sq0v4kuXE1o58TPfvaz1m7b0tKiadrKlSu7u7snJib+97//hRyP0QTdM/w+2OQdTYTyHmb37t0rVqyw9ib58Itf/OKBAwfeeOONgOJJRn8JIkfNUPbOdovrZI3h1vRenpqZmRFCZDKZejeMnXAGMr8cP35cCFEsFuXDfD4vhMhms/Kh9zQ1bbqN6CZrTCtWrNA07aKLLrrzzjunpqaeeuopBZuUcUNSc3xgHPAoqskak5y12bhx40MPPfTKK68oMlnQtL1bkfY36MI1RTVZY5KfMy+++OJIztHJ7p4h90E6mohoskbSNE3+P2VnZ+fvfve7SqXiezwJ6C++t0mTlL2z3TTz2EKIiYmJgYEB6xKVyWuQZLTWv2s/tZQN40XTtPHx8f7+/qgD8WRwcPDQoUNma1cqlba2Nl3Xp6amRD1patp0i/P9t6+vL+gDPffcc++++26NFVasWPHBBx987nOfe+eddwqFwle+8pWgQ/KOcUNSc3xgHPCor6/vb3/72+bNmwM9yuuvv/7SSy/VXmf58uUfffRRW1vbF77wheeff769vT3QkGpr2t4th/3JycmoA6EL1xLaOfrpp59+//33a6wgz9GrV69+++23T5069eUvfznokETSu2fIfZCOpmlaZ2fn+vXrAz3K3Nzcyy+//MEHH1RbYdmyZUKIlpaWDz744P7779+/f79f9+NPQH/x/X1mk5S9s93ies8aJMyhQ4esD1tbW4UQ8suBAJoE4wAQa3RhIAR0NDShpi37GP9091LI76dBHbqu53K5Uqlk/Y9Zv9LUVOmemJgI+hCXXnqp6/IVK1Z8+OGHq1at+va3v93f3//uu+/ecccdSl1Ws0RNVUiRYBzw7qqrrgq6s09NTd12222uT61cufL999/fuHHjd7/73TvvvPPBBx8UQkR7Wc0SJaw8okIXXlQI5+hVq1a5LpcX1Fx88cVbt241z9HhXFazRMlIvY/oaEKIPXv2BH11cCqVevnll53LNU1btmyZYRjXXXfdD37wg9tvv721tfW6667z67KaJYpLBuvVtGXfdFfWyBs+d3d3Rx0ILnDHHXcIIV599VX5UH7/c+lXC5PuEJg3GL7pppt+//vfl0qlo0eP6rre0tISdWi+oZDCwTigOPMGw6lU6tSpU6+88srDDz+8cePGqONaEsrDR3RhBZk3GL7pppsmJibefPPNGJ2jSb0rOlpU5C1srr322uHh4XPnzuXz+V27dq1evTrquD6R7Aw2bdnHdbLG/LGuUqlk/i3TJv+1riOEGBsbk0/JU5R5b205kSbzVCgU5MLBwUEhhFynVCoNDw+L+PyqWUzdeuutuq4/8sgjMmvPPfdcKpW68cYb5bPe0ySR7hDI+6u1tLTceOONR44cefPNN5999tnvfe971f5PTwWMG4pjHFDT8uXLhRCXXnrp7t27T548+cYbb/z6179W7T/k6d0qoAurQ/7n//Lly2+++eYnn3zyrbfeevbZZ/v6+uSUa8jonv6io4Xm448/FufnaK688spf/OIX//znP2dnZ3/84x9fdtllAR2U/uKqecveerfhGP0aVI2X4/pwZmZGNvHIyIj8lS9pfn5eLp+amjIMQ9f1bDYrbzQt7w6dTqflQ6V+ANILoeSvvdRQLBZHRkZkvrLZbGNpatp0GyH23zVr1shbu/32t7/997//HXk83jFumJQdHxgHvAjz16Auuuiiu+666/nnn//www+jjae2Zu7dKrS/iS5cTWjnxFWrVmma9tWvfnVkZOTNN9+MPB6jCbpn+H2wyTtaOO9hdu/eLYS4/PLL9+7d+5e//CW0eJLRX4LIUTOUvbPdYvxrUB5FfsfyqKj5ay9Ba9p0ixD776FDh7q7uzds2KBIPEFIfCEle3xIfPrC+eWR06dPz83NdXd3L/o9fHV+jciL5JVHvNrfi+TlSIR4TnziiSe2bt16+eWXKxJPXWKa+pj2wZi2tgjrPcwzzzyzZs2azs5O2VCRx+N6XKFqBpV9n6lyowm3dmvSGwwDaJjKd+EC4JdrrrnmmmuuiToKAPX54Q9/GHUIQBJ861vfijoEILb3rPHI+q2/aCNBCEg3fEEhxRrpQw2Uh/rIUdMi9WGiteOODDYgjo2W8MmatWvX2v5AgpFu+IJCijXShxooD/WRo6ZF6sNEa8cdGWxAHBst4V+DUvYLaQgC6YYvKKRYI32ogfJQHzlqWqQ+TLR23JHBBsSx0RJ+ZQ0AAAAAAEC8MFkDAAAAAACgECZrAAAAAAAAFMJkDQAAAAAAgEJcbjA8MTERfhwIQj6fjzoEhEfNdDOeKEvNgoEXZ8+eXbduXdRRXODs2bN09qicPXtWMNgqT80hl7LxBX0QanbwaNEm/jAsxsfHow4HwJIYymA8AYLT29sbdRf/VG9vb9TtAcRD1J31U5yjEWvj4+NR96FPRd0YSBRbbbtcWUPNJdXExMTAwAD5TSqZ36ijsKPe4oixQnF9fX1Rh2DX29s7OTkZdRRwp2na+Ph4f39/1IE0Nc7RcCXHc8bPumiaFnUIdoyxdeF9ZjXO2uaeNQAAAAAAAAphsgYAAAAAAEAhTNYAAAAAAAAohMkaAAAAAAAAhTBZAwAAAAAAoBAmawAAAAAAABTSyGSNZmF7qlQqDQ8P+xEY7IaHhyuVim1hjVw0jPxGIrT8KovqCo5rdfmI3C1R0AlSDQWzRIEWDNnxotn6rKAwvAmhMJKXiGbrTWSwATFtNF9apvErawzDsP06eqlUeuihhy666CL52XJoaMi2iXahhg/dsFKpNDQ0JI8+NjZme3Z2dtaMbXBw0OM+K5VKoVAYHR3t6emxLdcczIMuLCwMDg7KA01PT3vZ4ZYtW7Zv314qlawLnVnwC/mVkppf1VBdtuUhVJdfyJ3z2Vwu19PT09PTk8vlvDwVaIJUQ8E4n1WnYJozO7U3pM8KCkOZwlA/EUK9RlMKGWyA+o0W7Ntvw2J8fNy2xJVzQ8MwyuWyruv5fF7+nc1mhRDpdNq2WrFYFEIUi8VFj+K7YrEowzMMQ4aXyWSsK4yMjJjNMjU15XG36XQ6nU472ySfzztbW77wcrks9282lPVw1XYo96nrerlcti13XdmJ/JLfMHmPh+qKsLpckbtF1WjqbDYrm7pcLqdSqZGRES9P1ZWg3t7e3t5ej6GGwHs8FEwkBSOEGB8fX3S1ps1OjQ39SoHBOTpIsS6MJI2fUgiN5nFMC01ixlhJqfEwFo3m19tvw62WfJusyWQytoaTq2WzWefmHsP1lzmOm2HYIqlr+LZx7i2bzc7Pz5sPi8Wi2T62A7m2p+tCwzBSqZTtDFRjZRvy2/DOk5Tf0HiPh+qKsLpckTuPnHubn58XQpgHnZmZEULMzMzUfkrynqD4TtZQMJEUjPPNn6tmzo7rhj6mwOAcHaRYF0aSxk8phEbzOKaFJjFjrKTUeBiXRjP8ePttBDdZI2ezjh8/blstk8k4W9O2rTlJJoQYGRkxp8SKxaKcwDMMY2pqSgih67rtA4zcv67rtkMvqlwuiwun5WQJptNp24jvkWubWB9ms1lrQdu2TaVSi+5QOn78uHBMHFZb2Yb8kt8weYyH6oq2ulyRO4+cTS1flBmwbCL5v081npK8JyimkzUUTFQFIzx8kGjm7FTb0McUGJyjKYwqEjZ+htNoXsa0MCVpjFVqPIxLo5kBLPHttxHcZI18qdbXaZxvMnlRkPWThm1bXddlpovFoq7r5pVCuq7LA8lakaVjfiyRK8skySao9mHGaX5+XkY1NzdnewmSruv1XkZVLT0m5wcqSZ5UnFOY1XYo28HL/647kV/yGyaP8VBd0VaXK3LnkbOpU6mUbYncc+2nzAg9JiimkzUUTFQFIzx8kGjm7FTb0McUGJyjKYwqEjZ+htNoXsa0MCVpjFVqPIxLo5kBuL6oJda2P5M1sr2cqxnnv2lmHTeta9qmmuSdGsx5MtuBrA/lVJn1Kee311zJ9pJslySVy+WZmRn5WqwzhV5US480MzPjvFhLOn78uOs32artUH48s0Ve++gm8kt+w+QxHqor2upyRe48cjZ1jSWLruw9QTGdrKFgoioY4eGDRJNnx3VDH1NgcI6mMKpI3vgZQqN5GdPClLAxVp3xMEaN5tytaYm17c9kjWtw5hJ5CZM5OWdd0zZLJ1+MOUtXoynNWTGrRSM31R6yR0ZGrDOFXtQOIJ1OV5vI18/fM8n7Dj22vxP5lZo8v6FZyj2SqC5T0NXlitx55KW3mkvqWrm2mE7WUDBRFYzw8EGC7Dg39DEFBudoCqOKpI6fRpCNJmI4WUMGrRI5/tRYeSm1HcZkjXH+LkTyP4GrtY5zSY2mbKDgbObm5qrtxBakFzXisd4c1CabzVab4K8r3x5bg/xKTZ7f0PgyEBtUV8DV5YrceeTclTzN29aRl9fWeKrGDl0lcrLGoGDOr+N7wYglf5AwmiA7zg19TIHBOZrCqCLB42dwjeZlTAtTUsfYyMfDeDVajW2XUtvLRCg6OjqmpqZyuZy8YY9JJt728+NyMsyLM2fONBzSpk2bqj3V2trqPYZFTU9P9/b2OpfPzs6ePn16586dfh0oQuTXuTxJ+Y0W1eVcHpfqasLc2V7awsKCEOJLX/pS7acgUTAqF0yTZMe6oWopUBOFoUhhKJgI9RtNKWSwAQo2mu/8mayRDVSpVGqsI+/Ws3//fuvCO+64Qwjx6quvyodyD319fYseUf4C/NGjR+UmpVJpeHi4rpjlhuZtom1PeYnBoxdffLGjo8O2sFQqvfDCC/v27ZMPZ2dnBwcHve/T/C33cJDfGhKQ32hRXTUoXl3kzumWW24Rlpf2+uuvmwtrPGWV4O5PwTipUzBkx7khfVZQGG4bRlIYMU0EvclEBhsQx0arpvGWsV5m4+OvBclvkTlvtWC7UZC8OZD5ZbNsNmu9G7M8kLx9pry6ydyn+axJHl0m1fW+zbquZzIZuVq5XE6n0+b3C7LZrPnTXPPz87bbNdfYp/kqrKFaud4cVN5o2ha/9aA1dqjIr0GRXymO+Q1Nw3d6p7qkcKrLFbmrvU/zVbg29cjISCqVKpfL5XI5lUpZv61W4ymjKX8NioIxQikY0dAvlTRJdmpv6FcKDM7RFEYVSRo/Q2s0L2NamBIzxqo2Hsai0cwjWndrpcSvQckXZt7q0vYibZvb7uxVLBblJJYQIpvNmq/QtgfnDs3f50ulUmYW0+l0KpVyvXmY9afIMpmM9cac5lPpdNqZhhr7dL5Y2+t1vTmo61VY1ntZ19ihvJ21bZ+u7exEfslvmDzGQ3VFW12uyF3tfTpfrO31yj3rum6+6fHylPcExXSyhoKJqmCEhw8STZud2hsaPqXA4BxNYVSRyPEz6EYTMZysIYNWSRp/nIGJRt9+G8FN1hiGkclkPP4kVQiqNaVq+2xAOp12trNrRpzIb8j7bEAI+Q2N93iornC4VpcrchfoPqvxnqCYTtYYFIyvvBeMxw82ZKde3lNgcI72SfIKg/FTqqvRPI5poWGMNQIbDxPQaEusbd9uMLxjx44XX3yxUCj4tcOGFQqFvXv3qr/PBszOzs7Ozu7YsSP8Q5PfEESY32hRXSEIqLrInV+apPtTMH4JomDITl2apM8KCqNOwRVGghPRJL2JDDYg7o229JbxbbKmtbX18OHDjzzyyOzsrF/7bMD09PSll17a2dmp+D4bcObMmUOHDh0+fLi1tTX8o5PfoEWb32hRXUELrrrInS+ap/tTML4IqGDIjnfN02cFhVGPQAsjqYlont5EBhsQ60bzp2Wsl9nU9TUZ5+aGYZTLZXUuVUqYTCbj/LZbjVw4kV+VhZbf0NQbD9UVHNfqqoHchazeBMX3a1ASBbNE9RaMqOcrA2THi3pTYHCObg4NFAbjZwONVteYFoImH2NDGA9j2mi+1PbyxuZ3qj3V2tp6//33N7BPLMq1YWvkomHkNxKh5VdZVFdwgm5YcrdEzdZ6FMwSBdp6ZMeLJmwiCsOLEJooeYlI2MtZFBlsQEwbzZeYffsaFAAAAAAAAJaOyRoAAAAAAACFMFkDAAAAAACgECZrAAAAAAAAFOJyg+G+vr7w40AIzp49K8hvcsn8qoZ6iyPGCsUVCoXIfw/eplAoUDAqe+yxxyYnJ6OOoqlxjoarQqEgSET8McbWhfeZ3rU8/PDD5oO33367UqlEFwyCtXr16quvvjrqKBAUmd/+/v6oA/kE40l8MVYobt26dV1dXV1dXVEH8gk1P4XCdPXVV69evTrqKJod52i4Wrdu3bp166KOImauvvrqb37zm+vXr486kE+cPn2aMbYuvM+sxlnbWlP9NjAAAAAAAIDiuGcNAAAAAACAQpisAQAAAAAAUAiTNQAAACRGZ+kAAAAUSURBVAAAAAphsgYAAAAAAEAh/wez5tCtSRx1OQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot model architecture\n",
    "lstm_model = tf.keras.Sequential([\n",
    "        layers.LSTM(100, return_sequences=True, stateful=False, input_shape=(X.shape[1], X.shape[2]),\n",
    "                    recurrent_dropout=0.4, dropout=0.5),\n",
    "        layers.LSTM(50, return_sequences=True, dropout=0.5, recurrent_dropout=0.3, stateful=False),\n",
    "        layers.LSTM(50, return_sequences=False, dropout=0.5, recurrent_dropout=0.3, stateful=False),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    lstm_model, to_file='./Report/LSTM.png', show_shapes=True, show_dtype=False,\n",
    "    show_layer_names=False, rankdir='LR', expand_nested=False, dpi=96 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15486cfb-8a62-45fe-9dd0-dc9c530ba31f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 8s 75ms/step - loss: 0.2637 - auc: 0.5134 - val_loss: 0.7108 - val_auc: 0.5442\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2661 - auc: 0.5517 - val_loss: 0.6897 - val_auc: 0.5447\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 0.2650 - auc: 0.5836 - val_loss: 0.6405 - val_auc: 0.5218\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2621 - auc: 0.5794 - val_loss: 0.6305 - val_auc: 0.5339\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2586 - auc: 0.6021 - val_loss: 0.6114 - val_auc: 0.5231\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2630 - auc: 0.5716 - val_loss: 0.6150 - val_auc: 0.5243\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2563 - auc: 0.6027 - val_loss: 0.6176 - val_auc: 0.5239\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2591 - auc: 0.5913 - val_loss: 0.6485 - val_auc: 0.5347\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2613 - auc: 0.5739 - val_loss: 0.6448 - val_auc: 0.5325\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2611 - auc: 0.5774 - val_loss: 0.5838 - val_auc: 0.5178\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  0 {'lstm': [0.5047628138030441]}\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 11s 76ms/step - loss: 0.2681 - auc: 0.5211 - val_loss: 0.7077 - val_auc: 0.5498\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.2686 - auc: 0.564 - 1s 45ms/step - loss: 0.2685 - auc: 0.5642 - val_loss: 0.7049 - val_auc: 0.5498\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2652 - auc: 0.5891 - val_loss: 0.6816 - val_auc: 0.5498\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2623 - auc: 0.5814 - val_loss: 0.6938 - val_auc: 0.5498\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2604 - auc: 0.6016 - val_loss: 0.6913 - val_auc: 0.5498\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2544 - auc: 0.6091 - val_loss: 0.6966 - val_auc: 0.5498\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.2520 - auc: 0.6044 - val_loss: 0.6639 - val_auc: 0.5498\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2561 - auc: 0.6075 - val_loss: 0.7005 - val_auc: 0.5498\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 0.2564 - auc: 0.6056 - val_loss: 0.6372 - val_auc: 0.5454\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2623 - auc: 0.5694 - val_loss: 0.5715 - val_auc: 0.5709\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  1 {'lstm': [0.5047628138030441, 0.6553582459632444]}\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 7s 72ms/step - loss: 0.2658 - auc: 0.5197 - val_loss: 0.6901 - val_auc: 0.5433\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2662 - auc: 0.5531 - val_loss: 0.6807 - val_auc: 0.5412\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2632 - auc: 0.5568 - val_loss: 0.6848 - val_auc: 0.5520\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 0.2637 - auc: 0.5548 - val_loss: 0.6617 - val_auc: 0.5468\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2629 - auc: 0.5592 - val_loss: 0.6434 - val_auc: 0.5464\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2584 - auc: 0.5901 - val_loss: 0.6319 - val_auc: 0.5373\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2588 - auc: 0.6003 - val_loss: 0.6365 - val_auc: 0.5373\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2621 - auc: 0.5574 - val_loss: 0.6310 - val_auc: 0.5347\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2638 - auc: 0.5729 - val_loss: 0.6004 - val_auc: 0.5338\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 1, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  2 {'lstm': [0.5047628138030441, 0.6553582459632444, 0.5478469207406009]}\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 11s 74ms/step - loss: 0.2667 - auc: 0.5142 - val_loss: 0.6944 - val_auc: 0.5447\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 0.2656 - auc: 0.5352 - val_loss: 0.6849 - val_auc: 0.5382\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2631 - auc: 0.5606 - val_loss: 0.6730 - val_auc: 0.5442\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 0.2595 - auc: 0.5680 - val_loss: 0.6472 - val_auc: 0.5308\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 0.2619 - auc: 0.5755 - val_loss: 0.6267 - val_auc: 0.5286\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 0.2608 - auc: 0.5766 - val_loss: 0.6732 - val_auc: 0.5360\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 0.2598 - auc: 0.5762 - val_loss: 0.6186 - val_auc: 0.5282\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 0.2635 - auc: 0.5740 - val_loss: 0.6045 - val_auc: 0.5282\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 0.2580 - auc: 0.5944 - val_loss: 0.5995 - val_auc: 0.5253\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2631 - auc: 0.5764 - val_loss: 0.6548 - val_auc: 0.5295\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  3 {'lstm': [0.5047628138030441, 0.6553582459632444, 0.5478469207406009, 0.598707203764609]}\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 7s 74ms/step - loss: 0.2677 - auc: 0.5017 - val_loss: 0.7008 - val_auc: 0.5401\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 0.2644 - auc: 0.5593 - val_loss: 0.6831 - val_auc: 0.5400\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2623 - auc: 0.5774 - val_loss: 0.6564 - val_auc: 0.5292\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2592 - auc: 0.5741 - val_loss: 0.6627 - val_auc: 0.5400\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2564 - auc: 0.5859 - val_loss: 0.6434 - val_auc: 0.5400\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2559 - auc: 0.5928 - val_loss: 0.5671 - val_auc: 0.5329\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2615 - auc: 0.5789 - val_loss: 0.6651 - val_auc: 0.5271\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2589 - auc: 0.5641 - val_loss: 0.6414 - val_auc: 0.5263\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2610 - auc: 0.5840 - val_loss: 0.6291 - val_auc: 0.5241\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 1, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  4 {'lstm': [0.5047628138030441, 0.6553582459632444, 0.5478469207406009, 0.598707203764609, 0.5092215314332821]}\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 14s 132ms/step - loss: 0.2650 - auc: 0.5275 - val_loss: 0.6756 - val_auc: 0.5427\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.2619 - auc: 0.5902 - val_loss: 0.7382 - val_auc: 0.5462\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.2533 - auc: 0.6097 - val_loss: 0.6548 - val_auc: 0.5465\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 3s 101ms/step - loss: 0.2594 - auc: 0.6063 - val_loss: 0.6410 - val_auc: 0.5448\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.2633 - auc: 0.5799 - val_loss: 0.7044 - val_auc: 0.5465\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.2626 - auc: 0.5825 - val_loss: 0.6080 - val_auc: 0.5448\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 3, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 3, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  0 {'lstm': [0.6110021964068157]}\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 10s 135ms/step - loss: 0.2679 - auc: 0.5342 - val_loss: 0.6550 - val_auc: 0.5444\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 3s 112ms/step - loss: 0.2613 - auc: 0.6103 - val_loss: 0.6379 - val_auc: 0.5511\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 3s 109ms/step - loss: 0.2557 - auc: 0.6122 - val_loss: 0.6796 - val_auc: 0.5521\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.2618 - auc: 0.5713 - val_loss: 0.6612 - val_auc: 0.6201\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 3s 110ms/step - loss: 0.2599 - auc: 0.6081 - val_loss: 0.7039 - val_auc: 0.4838\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.2586 - auc: 0.6005 - val_loss: 0.6694 - val_auc: 0.5521\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 3, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 3, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  1 {'lstm': [0.6110021964068157, 0.5163497177274055]}\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 9s 137ms/step - loss: 0.2642 - auc: 0.5238 - val_loss: 0.6712 - val_auc: 0.5514\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.2645 - auc: 0.5782 - val_loss: 0.6009 - val_auc: 0.5500\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.2590 - auc: 0.5826 - val_loss: 0.6267 - val_auc: 0.5462\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.2647 - auc: 0.5715 - val_loss: 0.6061 - val_auc: 0.5358\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.2600 - auc: 0.5782 - val_loss: 0.6097 - val_auc: 0.4856\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.2622 - auc: 0.5791 - val_loss: 0.5908 - val_auc: 0.5354\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 3s 109ms/step - loss: 0.2639 - auc: 0.5719 - val_loss: 0.7156 - val_auc: 0.5492\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.2581 - auc: 0.6054 - val_loss: 0.6868 - val_auc: 0.5492\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.2573 - auc: 0.6016 - val_loss: 0.5872 - val_auc: 0.5237\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.2633 - auc: 0.5852 - val_loss: 0.7163 - val_auc: 0.5547\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.2593 - auc: 0.6033 - val_loss: 0.5961 - val_auc: 0.5399\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 3, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 3, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  2 {'lstm': [0.6110021964068157, 0.5163497177274055, 0.4884913859670196]}\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 10s 141ms/step - loss: 0.2673 - auc: 0.5408 - val_loss: 0.6675 - val_auc: 0.6159\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 3s 112ms/step - loss: 0.2608 - auc: 0.5750 - val_loss: 0.6449 - val_auc: 0.5436\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 3s 110ms/step - loss: 0.2529 - auc: 0.6009 - val_loss: 0.7298 - val_auc: 0.5432\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.2611 - auc: 0.5828 - val_loss: 0.7233 - val_auc: 0.5436\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 0.2566 - auc: 0.5966 - val_loss: 0.6237 - val_auc: 0.5436\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 0.2592 - auc: 0.5981 - val_loss: 0.7868 - val_auc: 0.5251\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.2563 - auc: 0.6098 - val_loss: 0.5719 - val_auc: 0.5362\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 3s 110ms/step - loss: 0.2572 - auc: 0.6080 - val_loss: 0.6565 - val_auc: 0.5457\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 3s 108ms/step - loss: 0.2586 - auc: 0.6025 - val_loss: 0.6529 - val_auc: 0.5436\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 0.2617 - auc: 0.6023 - val_loss: 0.5685 - val_auc: 0.5297\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 3, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 3, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  3 {'lstm': [0.6110021964068157, 0.5163497177274055, 0.4884913859670196, 0.5575210599984544]}\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 9s 134ms/step - loss: 0.2663 - auc: 0.5207 - val_loss: 0.6863 - val_auc: 0.5436\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.2595 - auc: 0.5718 - val_loss: 0.6688 - val_auc: 0.5436\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.2539 - auc: 0.6065 - val_loss: 0.7471 - val_auc: 0.5436\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.2524 - auc: 0.6133 - val_loss: 0.6305 - val_auc: 0.5436\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.2595 - auc: 0.6088 - val_loss: 0.6611 - val_auc: 0.5436\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.2576 - auc: 0.6005 - val_loss: 0.7283 - val_auc: 0.5436\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 3, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 3, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  4 {'lstm': [0.6110021964068157, 0.5163497177274055, 0.4884913859670196, 0.5575210599984544, 0.5344645479292074]}\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 11s 196ms/step - loss: 0.2670 - auc: 0.5230 - val_loss: 0.6001 - val_auc: 0.5287\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 0.2580 - auc: 0.5880 - val_loss: 0.6945 - val_auc: 0.5442\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 0.2521 - auc: 0.6182 - val_loss: 0.5901 - val_auc: 0.5490\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 0.2500 - auc: 0.6219 - val_loss: 0.7252 - val_auc: 0.5435\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 0.2540 - auc: 0.6163 - val_loss: 0.7072 - val_auc: 0.5472\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 0.2517 - auc: 0.6279 - val_loss: 0.6477 - val_auc: 0.5381\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 0.2563 - auc: 0.6312 - val_loss: 0.5715 - val_auc: 0.5326\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 0.2624 - auc: 0.6025 - val_loss: 0.6289 - val_auc: 0.5307\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 0.2612 - auc: 0.5860 - val_loss: 0.5754 - val_auc: 0.5986\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_30 (LSTM)               (None, 5, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 5, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  0 {'lstm': [0.6328096847813032]}\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 16s 206ms/step - loss: 0.2655 - auc: 0.5269 - val_loss: 0.6357 - val_auc: 0.5478\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 0.2588 - auc: 0.5944 - val_loss: 0.6359 - val_auc: 0.5744\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 4s 178ms/step - loss: 0.2610 - auc: 0.5937 - val_loss: 0.6671 - val_auc: 0.5478\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 0.2583 - auc: 0.5915 - val_loss: 0.7182 - val_auc: 0.5521\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 0.2534 - auc: 0.6327 - val_loss: 0.6929 - val_auc: 0.5531\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 0.2523 - auc: 0.6318 - val_loss: 0.6604 - val_auc: 0.5554\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 0.2539 - auc: 0.6272 - val_loss: 0.7006 - val_auc: 0.5468\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 4s 174ms/step - loss: 0.2508 - auc: 0.6505 - val_loss: 0.6038 - val_auc: 0.5433\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 4s 178ms/step - loss: 0.2581 - auc: 0.6187 - val_loss: 0.7448 - val_auc: 0.5758\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 5s 181ms/step - loss: 0.2579 - auc: 0.6084 - val_loss: 0.6571 - val_auc: 0.4311\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_33 (LSTM)               (None, 5, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 5, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  1 {'lstm': [0.6328096847813032, 0.4078763920586166]}\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 12s 210ms/step - loss: 0.2664 - auc: 0.5463 - val_loss: 0.6412 - val_auc: 0.5520\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 4s 178ms/step - loss: 0.2575 - auc: 0.6001 - val_loss: 0.7244 - val_auc: 0.5480\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 4s 174ms/step - loss: 0.2595 - auc: 0.5921 - val_loss: 0.8221 - val_auc: 0.5466\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 0.2582 - auc: 0.5979 - val_loss: 0.6458 - val_auc: 0.5503\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 5s 182ms/step - loss: 0.2538 - auc: 0.6068 - val_loss: 0.9695 - val_auc: 0.5505\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 4s 179ms/step - loss: 0.2590 - auc: 0.5979 - val_loss: 0.5876 - val_auc: 0.5412\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 0.2561 - auc: 0.6220 - val_loss: 0.6565 - val_auc: 0.5505\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 4s 174ms/step - loss: 0.2534 - auc: 0.6355 - val_loss: 0.5542 - val_auc: 0.6055\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 0.2547 - auc: 0.6212 - val_loss: 0.6333 - val_auc: 0.5332\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 0.2577 - auc: 0.6277 - val_loss: 0.6282 - val_auc: 0.5480\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 0.2560 - auc: 0.6159 - val_loss: 0.7262 - val_auc: 0.5483\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 4s 174ms/step - loss: 0.2606 - auc: 0.5990 - val_loss: 0.6117 - val_auc: 0.5641\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 4s 174ms/step - loss: 0.2609 - auc: 0.5960 - val_loss: 0.6063 - val_auc: 0.5418\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_36 (LSTM)               (None, 5, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 5, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  2 {'lstm': [0.6328096847813032, 0.4078763920586166, 0.5214407055956896]}\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 17s 206ms/step - loss: 0.2660 - auc: 0.5184 - val_loss: 0.6443 - val_auc: 0.5514- loss: 0.26\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 0.2596 - auc: 0.5890 - val_loss: 0.6638 - val_auc: 0.5404\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 0.2549 - auc: 0.6232 - val_loss: 0.7744 - val_auc: 0.5404\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 0.2603 - auc: 0.5555 - val_loss: 0.6798 - val_auc: 0.5630\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 4s 178ms/step - loss: 0.2611 - auc: 0.5883 - val_loss: 0.6423 - val_auc: 0.54272s - loss: 0.2631\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 0.2533 - auc: 0.6267 - val_loss: 0.6039 - val_auc: 0.5399\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 4s 174ms/step - loss: 0.2548 - auc: 0.6178 - val_loss: 0.5685 - val_auc: 0.4667\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 0.2598 - auc: 0.6063 - val_loss: 0.5745 - val_auc: 0.5515\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 0.2555 - auc: 0.6258 - val_loss: 0.6187 - val_auc: 0.5445- loss: 0.2557 - auc: 0.\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_39 (LSTM)               (None, 5, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, 5, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  3 {'lstm': [0.6328096847813032, 0.4078763920586166, 0.5214407055956896, 0.6460535580878123]}\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 11s 194ms/step - loss: 0.2659 - auc: 0.5267 - val_loss: 0.6332 - val_auc: 0.5436\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 0.2642 - auc: 0.5724 - val_loss: 0.7594 - val_auc: 0.5423\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 0.2588 - auc: 0.5846 - val_loss: 0.7261 - val_auc: 0.5439\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 0.2574 - auc: 0.6058 - val_loss: 0.6862 - val_auc: 0.5433\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 0.2555 - auc: 0.6103 - val_loss: 0.6735 - val_auc: 0.5418\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 0.2566 - auc: 0.6155 - val_loss: 0.6839 - val_auc: 0.5423\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 0.2564 - auc: 0.6189 - val_loss: 0.6694 - val_auc: 0.5521\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 0.2547 - auc: 0.6267 - val_loss: 0.7358 - val_auc: 0.5423\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 0.2535 - auc: 0.6296 - val_loss: 0.6738 - val_auc: 0.5482\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 0.2595 - auc: 0.6125 - val_loss: 0.5887 - val_auc: 0.5397\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_42 (LSTM)               (None, 5, 100)            728800    \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 5, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_44 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  4 {'lstm': [0.6328096847813032, 0.4078763920586166, 0.5214407055956896, 0.6460535580878123, 0.5840929387821696]}\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 15s 337ms/step - loss: 0.2673 - auc: 0.5210 - val_loss: 0.6843 - val_auc: 0.5542\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.2546 - auc: 0.6205 - val_loss: 0.6126 - val_auc: 0.5539\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 0.2556 - auc: 0.6147 - val_loss: 0.7104 - val_auc: 0.5542\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 0.2553 - auc: 0.6143 - val_loss: 0.5907 - val_auc: 0.5352\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 7s 294ms/step - loss: 0.2508 - auc: 0.6485 - val_loss: 0.5720 - val_auc: 0.5460\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_45 (LSTM)               (None, 10, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 10, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  0 {'lstm': [0.5633922902688883]}\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 19s 327ms/step - loss: 0.2667 - auc: 0.5387 - val_loss: 0.6837 - val_auc: 0.5496\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.2567 - auc: 0.6022 - val_loss: 0.6689 - val_auc: 0.5417\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.2527 - auc: 0.6027 - val_loss: 0.6740 - val_auc: 0.5431\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.2552 - auc: 0.6286 - val_loss: 0.5820 - val_auc: 0.5400\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.2575 - auc: 0.6082 - val_loss: 0.6564 - val_auc: 0.5580\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_48 (LSTM)               (None, 10, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 10, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_50 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  1 {'lstm': [0.5633922902688883, 0.45234076050586003]}\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 15s 328ms/step - loss: 0.2639 - auc: 0.5358 - val_loss: 0.6540 - val_auc: 0.5429\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 0.2552 - auc: 0.6119 - val_loss: 0.5601 - val_auc: 0.5450\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.2487 - auc: 0.6363 - val_loss: 0.5936 - val_auc: 0.5389\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.2519 - auc: 0.6145 - val_loss: 0.5862 - val_auc: 0.5423\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 7s 294ms/step - loss: 0.2490 - auc: 0.6411 - val_loss: 0.5637 - val_auc: 0.6333\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.2616 - auc: 0.6189 - val_loss: 0.5861 - val_auc: 0.5358\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 7s 287ms/step - loss: 0.2549 - auc: 0.6190 - val_loss: 0.5846 - val_auc: 0.5568\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_51 (LSTM)               (None, 10, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_52 (LSTM)               (None, 10, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  2 {'lstm': [0.5633922902688883, 0.45234076050586003, 0.657212536678278]}\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 20s 328ms/step - loss: 0.2637 - auc: 0.5380 - val_loss: 0.6674 - val_auc: 0.5306\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.2505 - auc: 0.6307 - val_loss: 0.5624 - val_auc: 0.4579\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 0.2543 - auc: 0.5991 - val_loss: 0.5574 - val_auc: 0.5442\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 0.2527 - auc: 0.6229 - val_loss: 0.6075 - val_auc: 0.5404\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.2513 - auc: 0.6391 - val_loss: 0.6253 - val_auc: 0.5378\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.2474 - auc: 0.6557 - val_loss: 0.5706 - val_auc: 0.5378\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 0.2452 - auc: 0.6699 - val_loss: 0.8364 - val_auc: 0.5712\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.2477 - auc: 0.6535 - val_loss: 0.7041 - val_auc: 0.5223\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.2546 - auc: 0.6250 - val_loss: 0.5671 - val_auc: 0.5313\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.2529 - auc: 0.6249 - val_loss: 0.5669 - val_auc: 0.5311\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_54 (LSTM)               (None, 10, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 10, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_56 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  3 {'lstm': [0.5633922902688883, 0.45234076050586003, 0.657212536678278, 0.5732913707676058]}\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 15s 331ms/step - loss: 0.2652 - auc: 0.5285 - val_loss: 0.5822 - val_auc: 0.5359\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 0.2542 - auc: 0.6149 - val_loss: 0.6198 - val_auc: 0.5513\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.2504 - auc: 0.6413 - val_loss: 0.5666 - val_auc: 0.5361\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.2494 - auc: 0.6370 - val_loss: 0.6496 - val_auc: 0.5338\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.2513 - auc: 0.6425 - val_loss: 0.6286 - val_auc: 0.5360\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 0.2516 - auc: 0.6245 - val_loss: 0.5770 - val_auc: 0.5356\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_57 (LSTM)               (None, 10, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_58 (LSTM)               (None, 10, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  4 {'lstm': [0.5633922902688883, 0.45234076050586003, 0.657212536678278, 0.5732913707676058, 0.5542010510678129]}\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 22s 606ms/step - loss: 0.2640 - auc: 0.5301 - val_loss: 0.6310 - val_auc: 0.5820\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 0.2512 - auc: 0.6125 - val_loss: 0.7278 - val_auc: 0.5424\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 0.2500 - auc: 0.6516 - val_loss: 0.6874 - val_auc: 0.5830\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 0.2418 - auc: 0.6791 - val_loss: 0.7815 - val_auc: 0.5810\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 14s 563ms/step - loss: 0.2470 - auc: 0.6745 - val_loss: 0.5514 - val_auc: 0.5936\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 14s 550ms/step - loss: 0.2476 - auc: 0.6780 - val_loss: 0.6101 - val_auc: 0.5752\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 14s 544ms/step - loss: 0.2408 - auc: 0.6853 - val_loss: 0.5608 - val_auc: 0.5817\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 14s 543ms/step - loss: 0.2314 - auc: 0.7162 - val_loss: 0.6616 - val_auc: 0.5822\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 14s 546ms/step - loss: 0.2342 - auc: 0.7130 - val_loss: 0.5662 - val_auc: 0.5818\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 14s 569ms/step - loss: 0.2320 - auc: 0.7292 - val_loss: 0.7477 - val_auc: 0.5832\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 14s 566ms/step - loss: 0.2317 - auc: 0.7360 - val_loss: 0.5553 - val_auc: 0.5799\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 14s 568ms/step - loss: 0.2408 - auc: 0.6977 - val_loss: 0.5711 - val_auc: 0.5123\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 14s 547ms/step - loss: 0.2541 - auc: 0.6561 - val_loss: 0.5544 - val_auc: 0.5804\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_60 (LSTM)               (None, 20, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_61 (LSTM)               (None, 20, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_62 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  0 {'lstm': [0.630116727010656]}\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 25s 561ms/step - loss: 0.2644 - auc: 0.5320 - val_loss: 0.6971 - val_auc: 0.5823\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 14s 538ms/step - loss: 0.2557 - auc: 0.6074 - val_loss: 0.7529 - val_auc: 0.5859\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 13s 518ms/step - loss: 0.2551 - auc: 0.6083 - val_loss: 0.5572 - val_auc: 0.5822\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 0.2484 - auc: 0.6505 - val_loss: 0.5894 - val_auc: 0.5153\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 14s 563ms/step - loss: 0.2495 - auc: 0.6595 - val_loss: 0.6163 - val_auc: 0.5756\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 14s 566ms/step - loss: 0.2497 - auc: 0.6723 - val_loss: 0.5885 - val_auc: 0.5753\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 14s 547ms/step - loss: 0.2462 - auc: 0.6751 - val_loss: 0.7281 - val_auc: 0.5828\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 14s 549ms/step - loss: 0.2460 - auc: 0.6804 - val_loss: 0.8037 - val_auc: 0.5829\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 13s 523ms/step - loss: 0.2422 - auc: 0.6946 - val_loss: 0.5789 - val_auc: 0.5440\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 14s 543ms/step - loss: 0.2420 - auc: 0.6897 - val_loss: 0.5714 - val_auc: 0.5149\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 0.2435 - auc: 0.6818 - val_loss: 0.5564 - val_auc: 0.5183\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 0.2394 - auc: 0.6941 - val_loss: 0.5655 - val_auc: 0.5164\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 13s 521ms/step - loss: 0.2382 - auc: 0.6997 - val_loss: 0.5641 - val_auc: 0.5163\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 0.2376 - auc: 0.7031 - val_loss: 0.5637 - val_auc: 0.5667\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 0.2457 - auc: 0.6771 - val_loss: 0.5688 - val_auc: 0.5264\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 13s 541ms/step - loss: 0.2373 - auc: 0.6968 - val_loss: 0.6739 - val_auc: 0.5144\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 0.2395 - auc: 0.6975 - val_loss: 0.6172 - val_auc: 0.5833\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 0.2383 - auc: 0.7012 - val_loss: 0.5523 - val_auc: 0.5732\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 13s 541ms/step - loss: 0.2363 - auc: 0.7074 - val_loss: 0.5559 - val_auc: 0.5913\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 0.2371 - auc: 0.7121 - val_loss: 0.6287 - val_auc: 0.5854\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 0.2410 - auc: 0.6992 - val_loss: 0.5545 - val_auc: 0.5865\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_63 (LSTM)               (None, 20, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_64 (LSTM)               (None, 20, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  1 {'lstm': [0.630116727010656, 0.6151333287574857]}\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 22s 593ms/step - loss: 0.2651 - auc: 0.5439 - val_loss: 0.5587 - val_auc: 0.5744\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 14s 547ms/step - loss: 0.2549 - auc: 0.6100 - val_loss: 0.6429 - val_auc: 0.5777\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 14s 549ms/step - loss: 0.2517 - auc: 0.6430 - val_loss: 0.6087 - val_auc: 0.5765\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 14s 559ms/step - loss: 0.2504 - auc: 0.6244 - val_loss: 0.5557 - val_auc: 0.5743\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 14s 563ms/step - loss: 0.2456 - auc: 0.6678 - val_loss: 0.7448 - val_auc: 0.5810\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 14s 556ms/step - loss: 0.2432 - auc: 0.6857 - val_loss: 0.6324 - val_auc: 0.5898\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 14s 559ms/step - loss: 0.2402 - auc: 0.6873 - val_loss: 0.5502 - val_auc: 0.5845\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 14s 560ms/step - loss: 0.2422 - auc: 0.6880 - val_loss: 0.5637 - val_auc: 0.5219\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 14s 547ms/step - loss: 0.2539 - auc: 0.6588 - val_loss: 0.7456 - val_auc: 0.5746\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 14s 556ms/step - loss: 0.2427 - auc: 0.6851 - val_loss: 0.5670 - val_auc: 0.5838\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 14s 545ms/step - loss: 0.2511 - auc: 0.6688 - val_loss: 0.8527 - val_auc: 0.5216\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_66 (LSTM)               (None, 20, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, 20, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_68 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  2 {'lstm': [0.630116727010656, 0.6151333287574857, 0.5088960910822451]}\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 27s 596ms/step - loss: 0.2671 - auc: 0.5624 - val_loss: 0.6903 - val_auc: 0.5499\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 14s 548ms/step - loss: 0.2581 - auc: 0.6116 - val_loss: 0.6178 - val_auc: 0.6267\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 14s 549ms/step - loss: 0.2488 - auc: 0.6436 - val_loss: 0.7628 - val_auc: 0.5891\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 14s 546ms/step - loss: 0.2520 - auc: 0.6293 - val_loss: 0.6020 - val_auc: 0.5988\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 14s 547ms/step - loss: 0.2515 - auc: 0.6451 - val_loss: 0.5762 - val_auc: 0.5906\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 14s 554ms/step - loss: 0.2493 - auc: 0.6712 - val_loss: 0.5552 - val_auc: 0.5760\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 14s 551ms/step - loss: 0.2450 - auc: 0.6704 - val_loss: 0.5658 - val_auc: 0.5899\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 0.2382 - auc: 0.7013 - val_loss: 0.5945 - val_auc: 0.5578\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 14s 557ms/step - loss: 0.2442 - auc: 0.6845 - val_loss: 0.6488 - val_auc: 0.5736\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 0.2393 - auc: 0.6888 - val_loss: 0.6060 - val_auc: 0.4889\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 14s 547ms/step - loss: 0.2394 - auc: 0.6854 - val_loss: 0.7158 - val_auc: 0.5491\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_69 (LSTM)               (None, 20, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_70 (LSTM)               (None, 20, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_71 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  3 {'lstm': [0.630116727010656, 0.6151333287574857, 0.5088960910822451, 0.5661329034030896]}\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 21s 589ms/step - loss: 0.2624 - auc: 0.5731 - val_loss: 0.7023 - val_auc: 0.5622\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 14s 579ms/step - loss: 0.2538 - auc: 0.6110 - val_loss: 0.7067 - val_auc: 0.5644\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 14s 554ms/step - loss: 0.2511 - auc: 0.6449 - val_loss: 0.5606 - val_auc: 0.5446\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 14s 548ms/step - loss: 0.2471 - auc: 0.6570 - val_loss: 0.6020 - val_auc: 0.5527\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 14s 561ms/step - loss: 0.2510 - auc: 0.6381 - val_loss: 0.7255 - val_auc: 0.5497\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 14s 565ms/step - loss: 0.2422 - auc: 0.6704 - val_loss: 0.6622 - val_auc: 0.5491\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 14s 559ms/step - loss: 0.2547 - auc: 0.6529 - val_loss: 0.5613 - val_auc: 0.5533\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 14s 565ms/step - loss: 0.2561 - auc: 0.6158 - val_loss: 0.6961 - val_auc: 0.5455\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 14s 549ms/step - loss: 0.2516 - auc: 0.6407 - val_loss: 0.5665 - val_auc: 0.5522\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_72 (LSTM)               (None, 20, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_73 (LSTM)               (None, 20, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_74 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  4 {'lstm': [0.630116727010656, 0.6151333287574857, 0.5088960910822451, 0.5661329034030896, 0.561111564322087]}\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 28s 827ms/step - loss: 0.2642 - auc: 0.5687 - val_loss: 0.7048 - val_auc: 0.5984\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 20s 796ms/step - loss: 0.2572 - auc: 0.5981 - val_loss: 0.6893 - val_auc: 0.5984\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 19s 780ms/step - loss: 0.2545 - auc: 0.6279 - val_loss: 0.5587 - val_auc: 0.6014\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 20s 784ms/step - loss: 0.2468 - auc: 0.6663 - val_loss: 0.6702 - val_auc: 0.6098\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 20s 789ms/step - loss: 0.2535 - auc: 0.6165 - val_loss: 0.5806 - val_auc: 0.5703\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 19s 758ms/step - loss: 0.2521 - auc: 0.6440 - val_loss: 0.6120 - val_auc: 0.4870\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 19s 771ms/step - loss: 0.2452 - auc: 0.6721 - val_loss: 0.6981 - val_auc: 0.6042\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 19s 770ms/step - loss: 0.2473 - auc: 0.6774 - val_loss: 0.6258 - val_auc: 0.6046\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 20s 802ms/step - loss: 0.2402 - auc: 0.6998 - val_loss: 0.5827 - val_auc: 0.5954\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 19s 772ms/step - loss: 0.2351 - auc: 0.6984 - val_loss: 0.6227 - val_auc: 0.5637\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 21s 832ms/step - loss: 0.2390 - auc: 0.7100 - val_loss: 0.5538 - val_auc: 0.5820\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 20s 810ms/step - loss: 0.2405 - auc: 0.6966 - val_loss: 0.5577 - val_auc: 0.5499\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 20s 814ms/step - loss: 0.2448 - auc: 0.6836 - val_loss: 0.6155 - val_auc: 0.5664\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 21s 825ms/step - loss: 0.2348 - auc: 0.7209 - val_loss: 0.5668 - val_auc: 0.6268\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 21s 830ms/step - loss: 0.2453 - auc: 0.6876 - val_loss: 0.6686 - val_auc: 0.5968\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 20s 804ms/step - loss: 0.2305 - auc: 0.7227 - val_loss: 0.5966 - val_auc: 0.5988\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 20s 781ms/step - loss: 0.2365 - auc: 0.7029 - val_loss: 0.6160 - val_auc: 0.6025\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 20s 781ms/step - loss: 0.2355 - auc: 0.7203 - val_loss: 0.5705 - val_auc: 0.5178\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 20s 799ms/step - loss: 0.2296 - auc: 0.7392 - val_loss: 0.8895 - val_auc: 0.4948\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 20s 810ms/step - loss: 0.2364 - auc: 0.7201 - val_loss: 0.7038 - val_auc: 0.5951\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 20s 817ms/step - loss: 0.2291 - auc: 0.7353 - val_loss: 0.5583 - val_auc: 0.5319\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 20s 797ms/step - loss: 0.2312 - auc: 0.7345 - val_loss: 0.5615 - val_auc: 0.5941\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_75 (LSTM)               (None, 30, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_76 (LSTM)               (None, 30, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_77 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  0 {'lstm': [0.6136458208212503]}\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 32s 811ms/step - loss: 0.2628 - auc: 0.5491 - val_loss: 0.5744 - val_auc: 0.5258\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 21s 827ms/step - loss: 0.2534 - auc: 0.6315 - val_loss: 0.6254 - val_auc: 0.5672\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 20s 787ms/step - loss: 0.2448 - auc: 0.6659 - val_loss: 0.5885 - val_auc: 0.5945\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 21s 843ms/step - loss: 0.2552 - auc: 0.6464 - val_loss: 0.5572 - val_auc: 0.5615\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 20s 782ms/step - loss: 0.2488 - auc: 0.6571 - val_loss: 0.7605 - val_auc: 0.5595\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 20s 814ms/step - loss: 0.2445 - auc: 0.6778 - val_loss: 0.6996 - val_auc: 0.5641\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 20s 822ms/step - loss: 0.2541 - auc: 0.6690 - val_loss: 0.5834 - val_auc: 0.6045\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 21s 834ms/step - loss: 0.2500 - auc: 0.6569 - val_loss: 0.6053 - val_auc: 0.4757\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 20s 794ms/step - loss: 0.2449 - auc: 0.6734 - val_loss: 0.6029 - val_auc: 0.6081\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_78 (LSTM)               (None, 30, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_79 (LSTM)               (None, 30, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_80 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  1 {'lstm': [0.6136458208212503, 0.6267781457521836]}\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 29s 877ms/step - loss: 0.2614 - auc: 0.5601 - val_loss: 0.7338 - val_auc: 0.6106\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 20s 798ms/step - loss: 0.2560 - auc: 0.6043 - val_loss: 0.5814 - val_auc: 0.6229\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 20s 805ms/step - loss: 0.2517 - auc: 0.6256 - val_loss: 0.6540 - val_auc: 0.6047\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 20s 808ms/step - loss: 0.2556 - auc: 0.6205 - val_loss: 0.7509 - val_auc: 0.6160\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 21s 830ms/step - loss: 0.2511 - auc: 0.6462 - val_loss: 0.6534 - val_auc: 0.6241\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 21s 831ms/step - loss: 0.2459 - auc: 0.6635 - val_loss: 0.5952 - val_auc: 0.6040\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 20s 783ms/step - loss: 0.2468 - auc: 0.6813 - val_loss: 0.7267 - val_auc: 0.6072\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 20s 795ms/step - loss: 0.2366 - auc: 0.7144 - val_loss: 0.6742 - val_auc: 0.5607\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 20s 807ms/step - loss: 0.2343 - auc: 0.7097 - val_loss: 0.8289 - val_auc: 0.5682\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 20s 794ms/step - loss: 0.2326 - auc: 0.7152 - val_loss: 0.7593 - val_auc: 0.6018\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 20s 810ms/step - loss: 0.2319 - auc: 0.7273 - val_loss: 0.6288 - val_auc: 0.5390\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 21s 824ms/step - loss: 0.2442 - auc: 0.6892 - val_loss: 0.6565 - val_auc: 0.5856\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 20s 813ms/step - loss: 0.2408 - auc: 0.6930 - val_loss: 0.5517 - val_auc: 0.6234\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 20s 815ms/step - loss: 0.2303 - auc: 0.7308 - val_loss: 0.5533 - val_auc: 0.6093\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 20s 809ms/step - loss: 0.2321 - auc: 0.7281 - val_loss: 0.5594 - val_auc: 0.6010\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 20s 822ms/step - loss: 0.2261 - auc: 0.7453 - val_loss: 0.6869 - val_auc: 0.5900\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 21s 837ms/step - loss: 0.2528 - auc: 0.6884 - val_loss: 0.5927 - val_auc: 0.6061\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 20s 813ms/step - loss: 0.2290 - auc: 0.7334 - val_loss: 0.7138 - val_auc: 0.5964\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 20s 802ms/step - loss: 0.2382 - auc: 0.7037 - val_loss: 0.6063 - val_auc: 0.6169\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_81 (LSTM)               (None, 30, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_82 (LSTM)               (None, 30, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_83 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  2 {'lstm': [0.6136458208212503, 0.6267781457521836, 0.6336097431233592]}\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 34s 857ms/step - loss: 0.2619 - auc: 0.5527 - val_loss: 0.6202 - val_auc: 0.6246\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 20s 817ms/step - loss: 0.2528 - auc: 0.6109 - val_loss: 0.5533 - val_auc: 0.6410\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 21s 839ms/step - loss: 0.2726 - auc: 0.6014 - val_loss: 0.5547 - val_auc: 0.6225\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 20s 790ms/step - loss: 0.2586 - auc: 0.6209 - val_loss: 0.6008 - val_auc: 0.5899\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 21s 824ms/step - loss: 0.2553 - auc: 0.6217 - val_loss: 0.5603 - val_auc: 0.5864\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_84 (LSTM)               (None, 30, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_85 (LSTM)               (None, 30, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_86 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  3 {'lstm': [0.6136458208212503, 0.6267781457521836, 0.6336097431233592, 0.5436206023030751]}\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 28s 848ms/step - loss: 0.2622 - auc: 0.5483 - val_loss: 0.6248 - val_auc: 0.5475\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 21s 825ms/step - loss: 0.2521 - auc: 0.6371 - val_loss: 0.5628 - val_auc: 0.5285\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 21s 823ms/step - loss: 0.2514 - auc: 0.6290 - val_loss: 0.6760 - val_auc: 0.5656\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 20s 811ms/step - loss: 0.2523 - auc: 0.6196 - val_loss: 0.7000 - val_auc: 0.5641\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 20s 802ms/step - loss: 0.2476 - auc: 0.6434 - val_loss: 0.7142 - val_auc: 0.5645\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 21s 838ms/step - loss: 0.2467 - auc: 0.6472 - val_loss: 0.6475 - val_auc: 0.5677\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 20s 806ms/step - loss: 0.2457 - auc: 0.6579 - val_loss: 0.6500 - val_auc: 0.5632\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 20s 813ms/step - loss: 0.2498 - auc: 0.6554 - val_loss: 0.5805 - val_auc: 0.5127\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 20s 811ms/step - loss: 0.2477 - auc: 0.6677 - val_loss: 0.6434 - val_auc: 0.5855\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 20s 814ms/step - loss: 0.2460 - auc: 0.6763 - val_loss: 0.6739 - val_auc: 0.5648\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 20s 818ms/step - loss: 0.2417 - auc: 0.6950 - val_loss: 0.5736 - val_auc: 0.5583\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 20s 806ms/step - loss: 0.2412 - auc: 0.6890 - val_loss: 0.6225 - val_auc: 0.5639\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 20s 788ms/step - loss: 0.2361 - auc: 0.7047 - val_loss: 0.7031 - val_auc: 0.5615\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 20s 798ms/step - loss: 0.2364 - auc: 0.7097 - val_loss: 0.6475 - val_auc: 0.5680\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 21s 829ms/step - loss: 0.2370 - auc: 0.7168 - val_loss: 0.7137 - val_auc: 0.5659\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 20s 818ms/step - loss: 0.2333 - auc: 0.7187 - val_loss: 0.7246 - val_auc: 0.5699\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 20s 816ms/step - loss: 0.2436 - auc: 0.6883 - val_loss: 0.5767 - val_auc: 0.5622\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 19s 771ms/step - loss: 0.2315 - auc: 0.7285 - val_loss: 0.6270 - val_auc: 0.5650\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 20s 802ms/step - loss: 0.2236 - auc: 0.7485 - val_loss: 0.6744 - val_auc: 0.5637\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 20s 819ms/step - loss: 0.2320 - auc: 0.7315 - val_loss: 0.6079 - val_auc: 0.5089\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 20s 799ms/step - loss: 0.2271 - auc: 0.7379 - val_loss: 0.6869 - val_auc: 0.5679\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 20s 796ms/step - loss: 0.2323 - auc: 0.7273 - val_loss: 0.5790 - val_auc: 0.5260\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_87 (LSTM)               (None, 30, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_88 (LSTM)               (None, 30, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_89 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  4 {'lstm': [0.6136458208212503, 0.6267781457521836, 0.6336097431233592, 0.5436206023030751, 0.4874058633096614]}\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2603 - auc: 0.5690 - val_loss: 0.6656 - val_auc: 0.6352\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2562 - auc: 0.6166 - val_loss: 0.5865 - val_auc: 0.6254\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2521 - auc: 0.6463 - val_loss: 0.7714 - val_auc: 0.6278\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2518 - auc: 0.6326 - val_loss: 0.5805 - val_auc: 0.6014\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2464 - auc: 0.6629 - val_loss: 0.7729 - val_auc: 0.4628\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2499 - auc: 0.6612 - val_loss: 0.5755 - val_auc: 0.6268\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2513 - auc: 0.6796 - val_loss: 0.5802 - val_auc: 0.5365\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2475 - auc: 0.6791 - val_loss: 0.7558 - val_auc: 0.5791\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2446 - auc: 0.6916 - val_loss: 0.6532 - val_auc: 0.5670\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2326 - auc: 0.7284 - val_loss: 0.7120 - val_auc: 0.5755\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2404 - auc: 0.7076 - val_loss: 0.5547 - val_auc: 0.6152\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2428 - auc: 0.6911 - val_loss: 0.6786 - val_auc: 0.5636\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.2381 - auc: 0.7082 - val_loss: 0.6595 - val_auc: 0.5804\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_90 (LSTM)               (None, 50, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_91 (LSTM)               (None, 50, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_92 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  0 {'lstm': [0.5758468177840315]}\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 43s 1s/step - loss: 0.2601 - auc: 0.5942 - val_loss: 0.6245 - val_auc: 0.6256\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2561 - auc: 0.6195 - val_loss: 0.6087 - val_auc: 0.5320\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2552 - auc: 0.6190 - val_loss: 0.6842 - val_auc: 0.6307\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2506 - auc: 0.6504 - val_loss: 0.6289 - val_auc: 0.5834\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2493 - auc: 0.6503 - val_loss: 0.5794 - val_auc: 0.6168\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2567 - auc: 0.6551 - val_loss: 0.6106 - val_auc: 0.6249\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2471 - auc: 0.6689 - val_loss: 0.5476 - val_auc: 0.6317\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2457 - auc: 0.6818 - val_loss: 0.6169 - val_auc: 0.4672\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2409 - auc: 0.6985 - val_loss: 0.6389 - val_auc: 0.6282\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.2367 - auc: 0.7103 - val_loss: 0.6459 - val_auc: 0.6304\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2363 - auc: 0.7145 - val_loss: 0.8323 - val_auc: 0.5498\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2557 - auc: 0.6885 - val_loss: 0.7986 - val_auc: 0.5392\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2440 - auc: 0.7082 - val_loss: 0.6419 - val_auc: 0.6362\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2469 - auc: 0.6755 - val_loss: 0.5832 - val_auc: 0.6247\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_93 (LSTM)               (None, 50, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_94 (LSTM)               (None, 50, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_95 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  1 {'lstm': [0.5758468177840315, 0.6298646979082657]}\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 44s 1s/step - loss: 0.2627 - auc: 0.5733 - val_loss: 0.6349 - val_auc: 0.6001\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.2557 - auc: 0.6247 - val_loss: 0.6620 - val_auc: 0.6071\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2517 - auc: 0.6228 - val_loss: 0.6884 - val_auc: 0.6124\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2581 - auc: 0.6260 - val_loss: 0.7305 - val_auc: 0.6490\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.2524 - auc: 0.6179 - val_loss: 0.6535 - val_auc: 0.6459\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2497 - auc: 0.6544 - val_loss: 0.5941 - val_auc: 0.4537\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2519 - auc: 0.6344 - val_loss: 0.6612 - val_auc: 0.6333\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2438 - auc: 0.6832 - val_loss: 0.6980 - val_auc: 0.6057\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.2613 - auc: 0.6620 - val_loss: 0.6423 - val_auc: 0.6495\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.2413 - auc: 0.6962 - val_loss: 0.6753 - val_auc: 0.6357\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2430 - auc: 0.6857 - val_loss: 0.7846 - val_auc: 0.6423\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2422 - auc: 0.6932 - val_loss: 0.6209 - val_auc: 0.6474\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.2448 - auc: 0.6767 - val_loss: 0.5758 - val_auc: 0.6260\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2408 - auc: 0.7009 - val_loss: 0.5913 - val_auc: 0.6382\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2405 - auc: 0.7080 - val_loss: 0.7943 - val_auc: 0.4437\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2359 - auc: 0.7128 - val_loss: 0.6145 - val_auc: 0.6414\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2381 - auc: 0.7113 - val_loss: 0.5429 - val_auc: 0.6528\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2310 - auc: 0.7298 - val_loss: 0.7103 - val_auc: 0.5370\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2380 - auc: 0.7160 - val_loss: 0.7318 - val_auc: 0.6341\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2327 - auc: 0.7340 - val_loss: 0.6093 - val_auc: 0.4501\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2275 - auc: 0.7422 - val_loss: 0.6590 - val_auc: 0.6284\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2345 - auc: 0.7187 - val_loss: 0.6475 - val_auc: 0.6135\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2313 - auc: 0.7342 - val_loss: 0.6457 - val_auc: 0.6003\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2242 - auc: 0.7609 - val_loss: 0.5954 - val_auc: 0.4449\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2237 - auc: 0.7557 - val_loss: 0.9790 - val_auc: 0.4704\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 37s 1s/step - loss: 0.2206 - auc: 0.7623 - val_loss: 0.6379 - val_auc: 0.5458\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.2360 - auc: 0.7325 - val_loss: 0.9183 - val_auc: 0.6313\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.2234 - auc: 0.7537 - val_loss: 0.7467 - val_auc: 0.5181\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 37s 1s/step - loss: 0.2323 - auc: 0.7309 - val_loss: 0.5975 - val_auc: 0.6147\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_96 (LSTM)               (None, 50, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_97 (LSTM)               (None, 50, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_98 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  2 {'lstm': [0.5758468177840315, 0.6298646979082657, 0.6284372479708976]}\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 43s 1s/step - loss: 0.2612 - auc: 0.5828 - val_loss: 0.6868 - val_auc: 0.6272\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2567 - auc: 0.6341 - val_loss: 0.7234 - val_auc: 0.6302\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2509 - auc: 0.6494 - val_loss: 0.7099 - val_auc: 0.6201\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2581 - auc: 0.6251 - val_loss: 0.6762 - val_auc: 0.6143\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2493 - auc: 0.6577 - val_loss: 0.6124 - val_auc: 0.6181\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2528 - auc: 0.6554 - val_loss: 0.5845 - val_auc: 0.4624\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2406 - auc: 0.6917 - val_loss: 0.5819 - val_auc: 0.6160\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2358 - auc: 0.7006 - val_loss: 0.7108 - val_auc: 0.4575\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2449 - auc: 0.6889 - val_loss: 0.6036 - val_auc: 0.5107\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2391 - auc: 0.6982 - val_loss: 0.5977 - val_auc: 0.6240\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2468 - auc: 0.6798 - val_loss: 0.5566 - val_auc: 0.6258\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_99 (LSTM)               (None, 50, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_100 (LSTM)              (None, 50, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_101 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  3 {'lstm': [0.5758468177840315, 0.6298646979082657, 0.6284372479708976, 0.6158729272753815]}\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 43s 1s/step - loss: 0.2583 - auc: 0.5933 - val_loss: 0.5726 - val_auc: 0.5589\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.2572 - auc: 0.6294 - val_loss: 0.6581 - val_auc: 0.4985\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2528 - auc: 0.6516 - val_loss: 0.5727 - val_auc: 0.5753\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.2446 - auc: 0.6745 - val_loss: 0.6875 - val_auc: 0.5806\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2446 - auc: 0.6816 - val_loss: 0.6353 - val_auc: 0.5015\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2398 - auc: 0.7009 - val_loss: 0.6995 - val_auc: 0.5017\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.2361 - auc: 0.7142 - val_loss: 0.7509 - val_auc: 0.5702\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.2401 - auc: 0.7043 - val_loss: 0.7304 - val_auc: 0.5768\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2358 - auc: 0.7169 - val_loss: 0.6535 - val_auc: 0.5303\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2302 - auc: 0.7294 - val_loss: 0.5659 - val_auc: 0.5231\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2383 - auc: 0.7113 - val_loss: 0.5740 - val_auc: 0.5785\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.2278 - auc: 0.7336 - val_loss: 0.5687 - val_auc: 0.5747\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2270 - auc: 0.7456 - val_loss: 0.6512 - val_auc: 0.5803\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2229 - auc: 0.7563 - val_loss: 0.5873 - val_auc: 0.5510\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.2206 - auc: 0.7678 - val_loss: 0.5615 - val_auc: 0.5589\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2274 - auc: 0.7499 - val_loss: 0.6461 - val_auc: 0.5200\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2411 - auc: 0.7184 - val_loss: 0.6092 - val_auc: 0.5827\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2198 - auc: 0.7664 - val_loss: 0.5578 - val_auc: 0.5740\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.2158 - auc: 0.7736 - val_loss: 0.6437 - val_auc: 0.5979\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_102 (LSTM)              (None, 50, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_103 (LSTM)              (None, 50, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_104 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  4 {'lstm': [0.5758468177840315, 0.6298646979082657, 0.6284372479708976, 0.6158729272753815, 0.6174604776175796]}\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 54s 2s/step - loss: 0.2610 - auc: 0.5852 - val_loss: 0.7185 - val_auc: 0.6171\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2559 - auc: 0.6239 - val_loss: 0.6324 - val_auc: 0.6304\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2577 - auc: 0.6485 - val_loss: 0.7072 - val_auc: 0.4855\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2497 - auc: 0.6455 - val_loss: 0.6493 - val_auc: 0.4882\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2521 - auc: 0.6536 - val_loss: 0.5632 - val_auc: 0.6175\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2579 - auc: 0.6472 - val_loss: 0.7155 - val_auc: 0.6300\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2569 - auc: 0.6447 - val_loss: 0.6205 - val_auc: 0.6229\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_105 (LSTM)              (None, 70, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_106 (LSTM)              (None, 70, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_107 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  0 {'lstm': [0.6299397704068501]}\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 59s 2s/step - loss: 0.2618 - auc: 0.5871 - val_loss: 0.6357 - val_auc: 0.6255\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2514 - auc: 0.6278 - val_loss: 0.6097 - val_auc: 0.5208\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2495 - auc: 0.6544 - val_loss: 0.5970 - val_auc: 0.6312\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2506 - auc: 0.6399 - val_loss: 0.7128 - val_auc: 0.6314\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2497 - auc: 0.6489 - val_loss: 0.6851 - val_auc: 0.6113\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2528 - auc: 0.6462 - val_loss: 0.6339 - val_auc: 0.6320\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2572 - auc: 0.6415 - val_loss: 0.7253 - val_auc: 0.4871\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2520 - auc: 0.6607 - val_loss: 0.6572 - val_auc: 0.6300\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2462 - auc: 0.6695 - val_loss: 0.7617 - val_auc: 0.4661\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2391 - auc: 0.6972 - val_loss: 0.6016 - val_auc: 0.6349\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.2367 - auc: 0.7038 - val_loss: 0.5972 - val_auc: 0.6365\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2377 - auc: 0.7138 - val_loss: 0.5749 - val_auc: 0.4719\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2381 - auc: 0.7190 - val_loss: 0.6738 - val_auc: 0.5032\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.2299 - auc: 0.7357 - val_loss: 0.7738 - val_auc: 0.4935\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.2419 - auc: 0.7121 - val_loss: 0.6957 - val_auc: 0.6308\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2343 - auc: 0.7382 - val_loss: 0.6193 - val_auc: 0.6349\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2256 - auc: 0.7496 - val_loss: 0.6314 - val_auc: 0.6347\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2281 - auc: 0.7434 - val_loss: 0.6077 - val_auc: 0.4642\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2187 - auc: 0.7685 - val_loss: 1.0365 - val_auc: 0.4595\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2401 - auc: 0.7082 - val_loss: 0.6254 - val_auc: 0.4834\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2217 - auc: 0.7577 - val_loss: 0.6594 - val_auc: 0.4726\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2360 - auc: 0.7325 - val_loss: 0.5739 - val_auc: 0.5586\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_108 (LSTM)              (None, 70, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_109 (LSTM)              (None, 70, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_110 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  1 {'lstm': [0.6299397704068501, 0.5527727491119996]}\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 54s 2s/step - loss: 0.2613 - auc: 0.5912 - val_loss: 0.6978 - val_auc: 0.6435\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2660 - auc: 0.6164 - val_loss: 0.7295 - val_auc: 0.6434\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2576 - auc: 0.6467 - val_loss: 0.5553 - val_auc: 0.6443\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2575 - auc: 0.6242 - val_loss: 0.6853 - val_auc: 0.4390\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2552 - auc: 0.6385 - val_loss: 0.7043 - val_auc: 0.5218\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2488 - auc: 0.6626 - val_loss: 0.7631 - val_auc: 0.6041\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2488 - auc: 0.6644 - val_loss: 0.7425 - val_auc: 0.4890\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2452 - auc: 0.6718 - val_loss: 0.7540 - val_auc: 0.4558\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2466 - auc: 0.6757 - val_loss: 0.7063 - val_auc: 0.4526\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2462 - auc: 0.6832 - val_loss: 0.6242 - val_auc: 0.4596\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2380 - auc: 0.7041 - val_loss: 0.6543 - val_auc: 0.4599\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2404 - auc: 0.6988 - val_loss: 0.5862 - val_auc: 0.6271\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2404 - auc: 0.7107 - val_loss: 0.6664 - val_auc: 0.6219\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2406 - auc: 0.6895 - val_loss: 0.6217 - val_auc: 0.4418\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2367 - auc: 0.7136 - val_loss: 0.5752 - val_auc: 0.6528\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2393 - auc: 0.6963 - val_loss: 0.6634 - val_auc: 0.6225\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2295 - auc: 0.7315 - val_loss: 0.8449 - val_auc: 0.4969\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2334 - auc: 0.7249 - val_loss: 0.7334 - val_auc: 0.6157\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2274 - auc: 0.7386 - val_loss: 0.6326 - val_auc: 0.6252\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2303 - auc: 0.7330 - val_loss: 1.1947 - val_auc: 0.4627\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.2315 - auc: 0.7339 - val_loss: 0.7676 - val_auc: 0.6210\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2284 - auc: 0.7330 - val_loss: 0.7182 - val_auc: 0.4487\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_111 (LSTM)              (None, 70, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_112 (LSTM)              (None, 70, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_113 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  2 {'lstm': [0.6299397704068501, 0.5527727491119996, 0.4514613398081576]}\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 65s 2s/step - loss: 0.2586 - auc: 0.5954 - val_loss: 0.7372 - val_auc: 0.6459\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2546 - auc: 0.6114 - val_loss: 0.5869 - val_auc: 0.6246\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2689 - auc: 0.6290 - val_loss: 0.7026 - val_auc: 0.6456\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2557 - auc: 0.6312 - val_loss: 0.6229 - val_auc: 0.6480\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2550 - auc: 0.6358 - val_loss: 0.7077 - val_auc: 0.6475\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2515 - auc: 0.6467 - val_loss: 0.8226 - val_auc: 0.6520\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 49s 2s/step - loss: 0.2534 - auc: 0.6433 - val_loss: 0.5833 - val_auc: 0.6492\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2533 - auc: 0.6439 - val_loss: 0.6711 - val_auc: 0.6211\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2458 - auc: 0.6767 - val_loss: 0.6108 - val_auc: 0.6380\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 49s 2s/step - loss: 0.2461 - auc: 0.6832 - val_loss: 1.1185 - val_auc: 0.4772\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2485 - auc: 0.6783 - val_loss: 0.7836 - val_auc: 0.6476\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2333 - auc: 0.7303 - val_loss: 0.6072 - val_auc: 0.6479\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2369 - auc: 0.7144 - val_loss: 0.6515 - val_auc: 0.6305\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2383 - auc: 0.7110 - val_loss: 0.7137 - val_auc: 0.6006\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2469 - auc: 0.6766 - val_loss: 0.5939 - val_auc: 0.4991\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_114 (LSTM)              (None, 70, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_115 (LSTM)              (None, 70, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_116 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  3 {'lstm': [0.6299397704068501, 0.5527727491119996, 0.4514613398081576, 0.5132982834276489]}\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 57s 2s/step - loss: 0.2587 - auc: 0.6105 - val_loss: 0.7006 - val_auc: 0.4849\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2599 - auc: 0.6160 - val_loss: 0.6777 - val_auc: 0.5670\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2490 - auc: 0.6509 - val_loss: 0.7061 - val_auc: 0.5789\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2492 - auc: 0.6707 - val_loss: 0.6530 - val_auc: 0.5784\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2467 - auc: 0.6804 - val_loss: 0.6464 - val_auc: 0.5101\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 49s 2s/step - loss: 0.2461 - auc: 0.6617 - val_loss: 0.6895 - val_auc: 0.5687\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 50s 2s/step - loss: 0.2484 - auc: 0.6663 - val_loss: 0.5775 - val_auc: 0.5823\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 49s 2s/step - loss: 0.2441 - auc: 0.6836 - val_loss: 0.5936 - val_auc: 0.5957\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2380 - auc: 0.7026 - val_loss: 0.5695 - val_auc: 0.5699\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2404 - auc: 0.7044 - val_loss: 0.6229 - val_auc: 0.5696\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2434 - auc: 0.6929 - val_loss: 0.7196 - val_auc: 0.5837\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2340 - auc: 0.7222 - val_loss: 0.6315 - val_auc: 0.5822\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2345 - auc: 0.7226 - val_loss: 0.7382 - val_auc: 0.5817\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2309 - auc: 0.7343 - val_loss: 0.6861 - val_auc: 0.5804\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2338 - auc: 0.7243 - val_loss: 0.9419 - val_auc: 0.5859\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2296 - auc: 0.7358 - val_loss: 0.6405 - val_auc: 0.5305\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2236 - auc: 0.7547 - val_loss: 0.7920 - val_auc: 0.5668\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2278 - auc: 0.7428 - val_loss: 0.6301 - val_auc: 0.5311\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.2228 - auc: 0.7647 - val_loss: 0.6008 - val_auc: 0.5028\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2288 - auc: 0.7381 - val_loss: 0.6059 - val_auc: 0.5805\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.2194 - auc: 0.7650 - val_loss: 0.7249 - val_auc: 0.4974\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2205 - auc: 0.7527 - val_loss: 0.5763 - val_auc: 0.4990\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2206 - auc: 0.7608 - val_loss: 0.5703 - val_auc: 0.4935\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2216 - auc: 0.7589 - val_loss: 0.5669 - val_auc: 0.4898\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2246 - auc: 0.7437 - val_loss: 0.6296 - val_auc: 0.4987\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.2202 - auc: 0.7587 - val_loss: 0.7559 - val_auc: 0.5289\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2141 - auc: 0.7794 - val_loss: 0.5699 - val_auc: 0.4966\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2390 - auc: 0.7272 - val_loss: 0.5987 - val_auc: 0.4972\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2221 - auc: 0.7504 - val_loss: 0.6220 - val_auc: 0.4937\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_117 (LSTM)              (None, 70, 100)           728800    \n",
      "_________________________________________________________________\n",
      "lstm_118 (LSTM)              (None, 70, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_119 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 779,251\n",
      "Trainable params: 779,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Cross fold:  4 {'lstm': [0.6299397704068501, 0.5527727491119996, 0.4514613398081576, 0.5132982834276489, 0.4923305968931672]}\n"
     ]
    }
   ],
   "source": [
    "lstm_scores = {}\n",
    "# use cross fold from above, training separately to tune LSTM\n",
    "for i in [1, 3, 5, 10, 20, 30, 50, 70]:\n",
    "    encounter_list = []\n",
    "    y = []\n",
    "    \n",
    "    # Loop through each admission\n",
    "    for admission in encounters['HADM_ID'].unique():\n",
    "        adm = encounters[encounters['HADM_ID'] == admission].copy()\n",
    "\n",
    "        if adm.shape[1] > 0:\n",
    "            y.append(adm['1YEAR'].head(1).values[0])\n",
    "            adm.drop(['SUBJECT_ID', 'EID', '1YEAR', 'HADM_ID'], axis=1, inplace=True)\n",
    "            encounter_list.append(adm.values.tolist())\n",
    "\n",
    "    X = sequence.pad_sequences(np.array(encounter_list, dtype=object), \n",
    "                               maxlen=i, \n",
    "                               padding='post', \n",
    "                               truncating='post')\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Train Model\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)\n",
    "    scores = {'lstm':[]}\n",
    "    \n",
    "    for j, (train, test) in enumerate(skf.split(X, y)):\n",
    "        scores['lstm'].append(lstm_fit_predict(X[train], y[train], X[test], y[test]))\n",
    "        print('Cross fold: ', j, scores)\n",
    "    lstm_scores[i] = scores\n",
    "pkl.dump(lstm_scores, open('./Model_Scores/lstm_scores.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc99b07a-b96e-4b36-9630-9c73fee4111c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'lstm': [0.5047628138030441,\n",
       "   0.6553582459632444,\n",
       "   0.5478469207406009,\n",
       "   0.598707203764609,\n",
       "   0.5092215314332821]},\n",
       " 3: {'lstm': [0.6110021964068157,\n",
       "   0.5163497177274055,\n",
       "   0.4884913859670196,\n",
       "   0.5575210599984544,\n",
       "   0.5344645479292074]},\n",
       " 5: {'lstm': [0.6328096847813032,\n",
       "   0.4078763920586166,\n",
       "   0.5214407055956896,\n",
       "   0.6460535580878123,\n",
       "   0.5840929387821696]},\n",
       " 10: {'lstm': [0.5633922902688883,\n",
       "   0.45234076050586003,\n",
       "   0.657212536678278,\n",
       "   0.5732913707676058,\n",
       "   0.5542010510678129]},\n",
       " 20: {'lstm': [0.630116727010656,\n",
       "   0.6151333287574857,\n",
       "   0.5088960910822451,\n",
       "   0.5661329034030896,\n",
       "   0.561111564322087]},\n",
       " 30: {'lstm': [0.6136458208212503,\n",
       "   0.6267781457521836,\n",
       "   0.6336097431233592,\n",
       "   0.5436206023030751,\n",
       "   0.4874058633096614]},\n",
       " 50: {'lstm': [0.5758468177840315,\n",
       "   0.6298646979082657,\n",
       "   0.6284372479708976,\n",
       "   0.6158729272753815,\n",
       "   0.6174604776175796]},\n",
       " 70: {'lstm': [0.6299397704068501,\n",
       "   0.5527727491119996,\n",
       "   0.4514613398081576,\n",
       "   0.5132982834276489,\n",
       "   0.4923305968931672]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dce9295f-7d77-4c80-8272-9116b4567933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'AUC ROC')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(7,7))\n",
    "\n",
    "plt.boxplot([lstm_scores[i]['lstm'] for i in [1, 3, 5, 10, 20, 30, 50, 70]], \n",
    "            labels=['1', '3', '5', '10', '20', '30', '50', '70'], \n",
    "            widths=0.75,\n",
    "            patch_artist=True,\n",
    "            boxprops=dict(facecolor='grey', color='grey'),\n",
    "            capprops=dict(color='grey'),\n",
    "            whiskerprops=dict(color='grey'),\n",
    "            flierprops=dict(color='grey', markeredgecolor='grey'),\n",
    "            medianprops=dict(color='black')\n",
    "           )\n",
    "\n",
    "plt.grid(axis='x')\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel('Number of Care Events per Admission', fontsize=16)\n",
    "plt.ylabel('AUC ROC', fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
